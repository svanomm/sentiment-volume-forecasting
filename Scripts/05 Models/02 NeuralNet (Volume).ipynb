{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26aa2b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Steven\\Desktop\\school github repos\\svo-directed-practicum\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer\n",
    "from sklearn.neural_network import MLPRegressor as nn\n",
    "from sklearn.metrics import r2_score as r2 \n",
    "import shap, datetime,warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67991b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the pickle file\n",
    "df = pickle.load(open('../../data/processed/merged_data_finance.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e23012",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_cols = [i for i in df.columns if any(x in i for x in ['Article Count', 'Tone', 'llm'])] + [i for i in df.columns if i.startswith('c') or i.startswith('v')]\n",
    "time_cols = ['hour_of_day_10','hour_of_day_11','hour_of_day_12','hour_of_day_13','hour_of_day_14','hour_of_day_15','hour_of_day_9','is_close','is_open','month_of_year_1','month_of_year_10','month_of_year_11','month_of_year_12','month_of_year_2','month_of_year_3','month_of_year_4','month_of_year_5','month_of_year_6','month_of_year_7','month_of_year_8','month_of_year_9','day_of_week_0','day_of_week_1','day_of_week_2','day_of_week_3','day_of_week_4']\n",
    "self_finance_vars = [i for i in df.columns if 'lag' in i and i not in sentiment_cols and all(x not in i for x in ['BNO','JETS','IYT','ITA'])]\n",
    "oil_vars          = [i for i in df.columns if 'lag' in i and 'BNO' in i]\n",
    "etf_finance_vars  = [i for i in df.columns if 'lag' in i and i not in sentiment_cols and any(x in i for x in ['JETS','IYT','ITA'])]\n",
    "finance_vars = self_finance_vars + oil_vars + etf_finance_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e9ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different sets of features to try\n",
    "feature_sets = {\n",
    "    'time_only': time_cols,\n",
    "    'sentiment_only': sentiment_cols,\n",
    "    'self_finance_only': self_finance_vars,\n",
    "    'finance_only': finance_vars,\n",
    "    'finance_time': finance_vars + time_cols,\n",
    "    'all': sentiment_cols + finance_vars + time_cols \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cefaa468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 time_only\n",
      "750 sentiment_only\n",
      "160 self_finance_only\n",
      "800 finance_only\n",
      "826 finance_time\n",
      "1576 all\n"
     ]
    }
   ],
   "source": [
    "for feature_set in feature_sets:\n",
    "    print(len(feature_sets[feature_set]), feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ef3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['Volume']\n",
    "y = df[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4701b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test splitting\n",
    "split_val  = round(0.8 * len(y))\n",
    "split_test = round(0.9 * len(y))\n",
    "\n",
    "y_train = y[:split_val]\n",
    "y_val   = y[split_val:split_test]\n",
    "y_test  = y[split_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7efbd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature set: time_only\n",
      "Iteration 1, loss = 303584267452.90911865\n",
      "Validation score: 0.044778\n",
      "Iteration 2, loss = 277699685192.38507080\n",
      "Validation score: 0.059669\n",
      "Iteration 3, loss = 275408917749.46673584\n",
      "Validation score: 0.063362\n",
      "Iteration 4, loss = 274660561926.17529297\n",
      "Validation score: 0.064376\n",
      "Iteration 5, loss = 274403223831.64285278\n",
      "Validation score: 0.064366\n",
      "Iteration 6, loss = 274288049479.90344238\n",
      "Validation score: 0.064319\n",
      "Iteration 7, loss = 274250595187.24658203\n",
      "Validation score: 0.064228\n",
      "Iteration 8, loss = 274226731111.18859863\n",
      "Validation score: 0.063975\n",
      "Iteration 9, loss = 274234254678.61810303\n",
      "Validation score: 0.064134\n",
      "Iteration 10, loss = 274237616339.04782104\n",
      "Validation score: 0.064042\n",
      "Iteration 11, loss = 274221236934.57812500\n",
      "Validation score: 0.063992\n",
      "Iteration 12, loss = 274225531837.78900146\n",
      "Validation score: 0.064106\n",
      "Iteration 13, loss = 274223395190.39309692\n",
      "Validation score: 0.063731\n",
      "Iteration 14, loss = 274235093322.76260376\n",
      "Validation score: 0.063874\n",
      "Iteration 15, loss = 274238701383.20782471\n",
      "Validation score: 0.063915\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.1106390477332253, 0.07802827565113601\n",
      "Processing feature set: sentiment_only\n",
      "Iteration 1, loss = 292736547720.56463623\n",
      "Validation score: 0.103197\n",
      "Iteration 2, loss = 248252871871.29223633\n",
      "Validation score: 0.148054\n",
      "Iteration 3, loss = 241168968111.09439087\n",
      "Validation score: 0.165542\n",
      "Iteration 4, loss = 236942489483.36486816\n",
      "Validation score: 0.179626\n",
      "Iteration 5, loss = 233101738364.27435303\n",
      "Validation score: 0.191071\n",
      "Iteration 6, loss = 229647594110.77713013\n",
      "Validation score: 0.201929\n",
      "Iteration 7, loss = 226542511760.93179321\n",
      "Validation score: 0.212097\n",
      "Iteration 8, loss = 223778998988.65161133\n",
      "Validation score: 0.220644\n",
      "Iteration 9, loss = 221307443995.50405884\n",
      "Validation score: 0.228186\n",
      "Iteration 10, loss = 218827619024.25445557\n",
      "Validation score: 0.234741\n",
      "Iteration 11, loss = 216691032399.26287842\n",
      "Validation score: 0.241170\n",
      "Iteration 12, loss = 214736160080.64041138\n",
      "Validation score: 0.245807\n",
      "Iteration 13, loss = 213115950658.06573486\n",
      "Validation score: 0.250850\n",
      "Iteration 14, loss = 211532610567.77740479\n",
      "Validation score: 0.256247\n",
      "Iteration 15, loss = 210232141736.83059692\n",
      "Validation score: 0.259775\n",
      "Iteration 16, loss = 208777888398.47775269\n",
      "Validation score: 0.263624\n",
      "Iteration 17, loss = 207487009048.99533081\n",
      "Validation score: 0.265890\n",
      "Iteration 18, loss = 206211753396.43835449\n",
      "Validation score: 0.271918\n",
      "Iteration 19, loss = 205049343987.93688965\n",
      "Validation score: 0.276097\n",
      "Iteration 20, loss = 203931884136.53921509\n",
      "Validation score: 0.279595\n",
      "Iteration 21, loss = 202785319122.19839478\n",
      "Validation score: 0.282123\n",
      "Iteration 22, loss = 201727515512.65872192\n",
      "Validation score: 0.285254\n",
      "Iteration 23, loss = 200763772414.31488037\n",
      "Validation score: 0.288817\n",
      "Iteration 24, loss = 199803304495.82693481\n",
      "Validation score: 0.291464\n",
      "Iteration 25, loss = 199006431602.81402588\n",
      "Validation score: 0.290529\n",
      "Iteration 26, loss = 198259127765.95129395\n",
      "Validation score: 0.296578\n",
      "Iteration 27, loss = 197560959837.17800903\n",
      "Validation score: 0.298898\n",
      "Iteration 28, loss = 196972920994.89694214\n",
      "Validation score: 0.300109\n",
      "Iteration 29, loss = 196346043778.74114990\n",
      "Validation score: 0.301681\n",
      "Iteration 30, loss = 195831107264.25518799\n",
      "Validation score: 0.303781\n",
      "Iteration 31, loss = 195322363930.98379517\n",
      "Validation score: 0.304304\n",
      "Iteration 32, loss = 194865840884.55560303\n",
      "Validation score: 0.305326\n",
      "Iteration 33, loss = 194347728348.69357300\n",
      "Validation score: 0.308096\n",
      "Iteration 34, loss = 193831657562.33734131\n",
      "Validation score: 0.309928\n",
      "Iteration 35, loss = 193412129667.84082031\n",
      "Validation score: 0.309297\n",
      "Iteration 36, loss = 192978983785.23928833\n",
      "Validation score: 0.312693\n",
      "Iteration 37, loss = 192588864183.87670898\n",
      "Validation score: 0.313639\n",
      "Iteration 38, loss = 192197213463.76895142\n",
      "Validation score: 0.314157\n",
      "Iteration 39, loss = 191795443331.62307739\n",
      "Validation score: 0.315063\n",
      "Iteration 40, loss = 191503197555.12310791\n",
      "Validation score: 0.314245\n",
      "Iteration 41, loss = 191077167507.52099609\n",
      "Validation score: 0.317350\n",
      "Iteration 42, loss = 190792700146.44418335\n",
      "Validation score: 0.319317\n",
      "Iteration 43, loss = 190424860553.33349609\n",
      "Validation score: 0.320505\n",
      "Iteration 44, loss = 190076608933.32409668\n",
      "Validation score: 0.321355\n",
      "Iteration 45, loss = 189792254422.90252686\n",
      "Validation score: 0.321753\n",
      "Iteration 46, loss = 189438267405.74987793\n",
      "Validation score: 0.323348\n",
      "Iteration 47, loss = 189158996558.13165283\n",
      "Validation score: 0.323361\n",
      "Iteration 48, loss = 188933240349.06750488\n",
      "Validation score: 0.324994\n",
      "Iteration 49, loss = 188547433053.03781128\n",
      "Validation score: 0.326154\n",
      "Iteration 50, loss = 188281662159.11724854\n",
      "Validation score: 0.325445\n",
      "Iteration 51, loss = 187947810234.47305298\n",
      "Validation score: 0.326075\n",
      "Iteration 52, loss = 187614617472.32257080\n",
      "Validation score: 0.327414\n",
      "Iteration 53, loss = 187375640264.90615845\n",
      "Validation score: 0.329708\n",
      "Iteration 54, loss = 187019927875.50207520\n",
      "Validation score: 0.331452\n",
      "Iteration 55, loss = 186858507721.53082275\n",
      "Validation score: 0.329617\n",
      "Iteration 56, loss = 186462374050.48364258\n",
      "Validation score: 0.328489\n",
      "Iteration 57, loss = 186315856178.56228638\n",
      "Validation score: 0.332957\n",
      "Iteration 58, loss = 185912750453.58471680\n",
      "Validation score: 0.328442\n",
      "Iteration 59, loss = 185711536947.43875122\n",
      "Validation score: 0.335823\n",
      "Iteration 60, loss = 185464214282.04306030\n",
      "Validation score: 0.335703\n",
      "Iteration 61, loss = 185025014091.47329712\n",
      "Validation score: 0.335156\n",
      "Iteration 62, loss = 184691636673.34243774\n",
      "Validation score: 0.330455\n",
      "Iteration 63, loss = 184665519864.06237793\n",
      "Validation score: 0.339608\n",
      "Iteration 64, loss = 184089808363.76110840\n",
      "Validation score: 0.339122\n",
      "Iteration 65, loss = 183834905375.91839600\n",
      "Validation score: 0.339100\n",
      "Iteration 66, loss = 183487780269.11679077\n",
      "Validation score: 0.340805\n",
      "Iteration 67, loss = 183275671495.34472656\n",
      "Validation score: 0.340607\n",
      "Iteration 68, loss = 182896308325.20462036\n",
      "Validation score: 0.344966\n",
      "Iteration 69, loss = 182722155302.24859619\n",
      "Validation score: 0.345229\n",
      "Iteration 70, loss = 182370936943.29003906\n",
      "Validation score: 0.346400\n",
      "Iteration 71, loss = 182155456127.35757446\n",
      "Validation score: 0.346172\n",
      "Iteration 72, loss = 181758078285.79284668\n",
      "Validation score: 0.343527\n",
      "Iteration 73, loss = 181271161846.13824463\n",
      "Validation score: 0.339413\n",
      "Iteration 74, loss = 181149281893.50836182\n",
      "Validation score: 0.350134\n",
      "Iteration 75, loss = 180717452762.26174927\n",
      "Validation score: 0.351870\n",
      "Iteration 76, loss = 180446984127.64709473\n",
      "Validation score: 0.346953\n",
      "Iteration 77, loss = 180039626133.00268555\n",
      "Validation score: 0.353311\n",
      "Iteration 78, loss = 179754416837.15606689\n",
      "Validation score: 0.355166\n",
      "Iteration 79, loss = 179422569341.58819580\n",
      "Validation score: 0.354908\n",
      "Iteration 80, loss = 179239502721.94992065\n",
      "Validation score: 0.359067\n",
      "Iteration 81, loss = 178894685706.29299927\n",
      "Validation score: 0.357384\n",
      "Iteration 82, loss = 178490253305.55401611\n",
      "Validation score: 0.358281\n",
      "Iteration 83, loss = 178332192766.21740723\n",
      "Validation score: 0.359351\n",
      "Iteration 84, loss = 178113200018.62240601\n",
      "Validation score: 0.359121\n",
      "Iteration 85, loss = 177686429095.97271729\n",
      "Validation score: 0.362844\n",
      "Iteration 86, loss = 177430872346.39041138\n",
      "Validation score: 0.360598\n",
      "Iteration 87, loss = 177044545181.63851929\n",
      "Validation score: 0.362532\n",
      "Iteration 88, loss = 176735298235.44732666\n",
      "Validation score: 0.368127\n",
      "Iteration 89, loss = 176321696634.40054321\n",
      "Validation score: 0.368437\n",
      "Iteration 90, loss = 176210074026.93234253\n",
      "Validation score: 0.367396\n",
      "Iteration 91, loss = 175923626794.32803345\n",
      "Validation score: 0.366428\n",
      "Iteration 92, loss = 175717694279.37527466\n",
      "Validation score: 0.372857\n",
      "Iteration 93, loss = 175488174505.49209595\n",
      "Validation score: 0.373104\n",
      "Iteration 94, loss = 174908893878.60202026\n",
      "Validation score: 0.373809\n",
      "Iteration 95, loss = 174684126228.71185303\n",
      "Validation score: 0.375684\n",
      "Iteration 96, loss = 174431147850.39184570\n",
      "Validation score: 0.370898\n",
      "Iteration 97, loss = 174073641072.82836914\n",
      "Validation score: 0.345278\n",
      "Iteration 98, loss = 173740200277.30554199\n",
      "Validation score: 0.379144\n",
      "Iteration 99, loss = 173542958817.68572998\n",
      "Validation score: 0.378528\n",
      "Iteration 100, loss = 173132947506.46456909\n",
      "Validation score: 0.370960\n",
      "Iteration 101, loss = 172948894973.82086182\n",
      "Validation score: 0.379189\n",
      "Iteration 102, loss = 172820701932.37445068\n",
      "Validation score: 0.381231\n",
      "Iteration 103, loss = 172408222058.86642456\n",
      "Validation score: 0.384903\n",
      "Iteration 104, loss = 172323003195.97714233\n",
      "Validation score: 0.383442\n",
      "Iteration 105, loss = 171829237780.91476440\n",
      "Validation score: 0.386510\n",
      "Iteration 106, loss = 171527671481.91256714\n",
      "Validation score: 0.386668\n",
      "Iteration 107, loss = 171385660357.59848022\n",
      "Validation score: 0.387406\n",
      "Iteration 108, loss = 170819958100.29598999\n",
      "Validation score: 0.389063\n",
      "Iteration 109, loss = 170837901087.25970459\n",
      "Validation score: 0.368817\n",
      "Iteration 110, loss = 170522294211.86553955\n",
      "Validation score: 0.391613\n",
      "Iteration 111, loss = 169910155141.54409790\n",
      "Validation score: 0.387105\n",
      "Iteration 112, loss = 169898827729.93731689\n",
      "Validation score: 0.393571\n",
      "Iteration 113, loss = 169615603532.83343506\n",
      "Validation score: 0.393808\n",
      "Iteration 114, loss = 169319200518.98889160\n",
      "Validation score: 0.393247\n",
      "Iteration 115, loss = 168930742557.23486328\n",
      "Validation score: 0.386067\n",
      "Iteration 116, loss = 169657610662.37094116\n",
      "Validation score: 0.394886\n",
      "Iteration 117, loss = 168496005365.33956909\n",
      "Validation score: 0.394998\n",
      "Iteration 118, loss = 168382597198.98611450\n",
      "Validation score: 0.394133\n",
      "Iteration 119, loss = 167838575039.43789673\n",
      "Validation score: 0.386860\n",
      "Iteration 120, loss = 168183008901.88778687\n",
      "Validation score: 0.400324\n",
      "Iteration 121, loss = 167671936263.24539185\n",
      "Validation score: 0.397432\n",
      "Iteration 122, loss = 167216937223.33413696\n",
      "Validation score: 0.398482\n",
      "Iteration 123, loss = 167195023048.09927368\n",
      "Validation score: 0.397991\n",
      "Iteration 124, loss = 167060598982.24859619\n",
      "Validation score: 0.401996\n",
      "Iteration 125, loss = 166839881365.28692627\n",
      "Validation score: 0.402497\n",
      "Iteration 126, loss = 166521664714.91098022\n",
      "Validation score: 0.399436\n",
      "Iteration 127, loss = 165947226352.88040161\n",
      "Validation score: 0.402369\n",
      "Iteration 128, loss = 166123184465.11987305\n",
      "Validation score: 0.402941\n",
      "Iteration 129, loss = 165633509140.56338501\n",
      "Validation score: 0.403508\n",
      "Iteration 130, loss = 165407707589.98001099\n",
      "Validation score: 0.404987\n",
      "Iteration 131, loss = 165342005649.78079224\n",
      "Validation score: 0.405442\n",
      "Iteration 132, loss = 165027290929.57452393\n",
      "Validation score: 0.398792\n",
      "Iteration 133, loss = 164639328195.78607178\n",
      "Validation score: 0.405348\n",
      "Iteration 134, loss = 164609498766.48706055\n",
      "Validation score: 0.407943\n",
      "Iteration 135, loss = 164386192099.67068481\n",
      "Validation score: 0.409940\n",
      "Iteration 136, loss = 163838041380.12536621\n",
      "Validation score: 0.404378\n",
      "Iteration 137, loss = 164115151965.05154419\n",
      "Validation score: 0.411458\n",
      "Iteration 138, loss = 163532409108.52151489\n",
      "Validation score: 0.410587\n",
      "Iteration 139, loss = 163286281285.20910645\n",
      "Validation score: 0.412250\n",
      "Iteration 140, loss = 163247141826.40078735\n",
      "Validation score: 0.408729\n",
      "Iteration 141, loss = 162930696606.18698120\n",
      "Validation score: 0.406747\n",
      "Iteration 142, loss = 162421843606.58337402\n",
      "Validation score: 0.411437\n",
      "Iteration 143, loss = 162830443967.03561401\n",
      "Validation score: 0.413716\n",
      "Iteration 144, loss = 162171305981.56057739\n",
      "Validation score: 0.404224\n",
      "Iteration 145, loss = 162550641788.32965088\n",
      "Validation score: 0.415456\n",
      "Iteration 146, loss = 161823990673.89682007\n",
      "Validation score: 0.416018\n",
      "Iteration 147, loss = 161583345672.19598389\n",
      "Validation score: 0.416496\n",
      "Iteration 148, loss = 161109522155.18017578\n",
      "Validation score: 0.415818\n",
      "Iteration 149, loss = 161361657215.32553101\n",
      "Validation score: 0.412100\n",
      "Iteration 150, loss = 161243211447.00213623\n",
      "Validation score: 0.416776\n",
      "Iteration 151, loss = 160435049645.66348267\n",
      "Validation score: 0.416587\n",
      "Iteration 152, loss = 160507574929.35583496\n",
      "Validation score: 0.419298\n",
      "Iteration 153, loss = 160278478207.27835083\n",
      "Validation score: 0.419842\n",
      "Iteration 154, loss = 159903238504.42938232\n",
      "Validation score: 0.412768\n",
      "Iteration 155, loss = 159761098968.80725098\n",
      "Validation score: 0.421313\n",
      "Iteration 156, loss = 159720608573.56912231\n",
      "Validation score: 0.419940\n",
      "Iteration 157, loss = 159314765550.91000366\n",
      "Validation score: 0.416629\n",
      "Iteration 158, loss = 159204124818.89849854\n",
      "Validation score: 0.417150\n",
      "Iteration 159, loss = 159129526545.18432617\n",
      "Validation score: 0.422279\n",
      "Iteration 160, loss = 158814517182.81280518\n",
      "Validation score: 0.421199\n",
      "Iteration 161, loss = 158606718688.86761475\n",
      "Validation score: 0.421966\n",
      "Iteration 162, loss = 158448311693.11773682\n",
      "Validation score: 0.415274\n",
      "Iteration 163, loss = 158329096574.50228882\n",
      "Validation score: 0.427149\n",
      "Iteration 164, loss = 158220573606.67596436\n",
      "Validation score: 0.420137\n",
      "Iteration 165, loss = 157739342878.98611450\n",
      "Validation score: 0.421210\n",
      "Iteration 166, loss = 157633611991.10247803\n",
      "Validation score: 0.422209\n",
      "Iteration 167, loss = 157738169954.54324341\n",
      "Validation score: 0.426801\n",
      "Iteration 168, loss = 157420658701.84536743\n",
      "Validation score: 0.425240\n",
      "Iteration 169, loss = 157269926976.89151001\n",
      "Validation score: 0.425398\n",
      "Iteration 170, loss = 157015129757.98837280\n",
      "Validation score: 0.426650\n",
      "Iteration 171, loss = 156571370393.75750732\n",
      "Validation score: 0.413693\n",
      "Iteration 172, loss = 156515381680.90728760\n",
      "Validation score: 0.427114\n",
      "Iteration 173, loss = 156223419774.69494629\n",
      "Validation score: 0.426569\n",
      "Iteration 174, loss = 156254762993.18905640\n",
      "Validation score: 0.421594\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "-0.08526754412719795, -0.020669143926347777\n",
      "Processing feature set: self_finance_only\n",
      "Iteration 1, loss = 299183493860.55548096\n",
      "Validation score: 0.101751\n",
      "Iteration 2, loss = 237823480331.62841797\n",
      "Validation score: 0.279081\n",
      "Iteration 3, loss = 192887969963.47598267\n",
      "Validation score: 0.431132\n",
      "Iteration 4, loss = 146765194552.11489868\n",
      "Validation score: 0.550398\n",
      "Iteration 5, loss = 126595857665.58691406\n",
      "Validation score: 0.574725\n",
      "Iteration 6, loss = 120974340859.75378418\n",
      "Validation score: 0.587918\n",
      "Iteration 7, loss = 116701389385.56817627\n",
      "Validation score: 0.602013\n",
      "Iteration 8, loss = 112812040485.18106079\n",
      "Validation score: 0.614572\n",
      "Iteration 9, loss = 109083136734.72987366\n",
      "Validation score: 0.626008\n",
      "Iteration 10, loss = 105627837770.37673950\n",
      "Validation score: 0.636378\n",
      "Iteration 11, loss = 102458176192.17726135\n",
      "Validation score: 0.644893\n",
      "Iteration 12, loss = 99558761025.45852661\n",
      "Validation score: 0.654891\n",
      "Iteration 13, loss = 97008413453.05258179\n",
      "Validation score: 0.663237\n",
      "Iteration 14, loss = 94729015563.65399170\n",
      "Validation score: 0.668216\n",
      "Iteration 15, loss = 92691854252.78944397\n",
      "Validation score: 0.676327\n",
      "Iteration 16, loss = 90903491370.63934326\n",
      "Validation score: 0.681110\n",
      "Iteration 17, loss = 89480826694.29080200\n",
      "Validation score: 0.684309\n",
      "Iteration 18, loss = 88262126906.88281250\n",
      "Validation score: 0.689296\n",
      "Iteration 19, loss = 87096167927.77449036\n",
      "Validation score: 0.692899\n",
      "Iteration 20, loss = 86084825447.62974548\n",
      "Validation score: 0.695751\n",
      "Iteration 21, loss = 85205559436.03492737\n",
      "Validation score: 0.698196\n",
      "Iteration 22, loss = 84301760259.91441345\n",
      "Validation score: 0.701825\n",
      "Iteration 23, loss = 83483662076.61285400\n",
      "Validation score: 0.700938\n",
      "Iteration 24, loss = 82747860984.11434937\n",
      "Validation score: 0.706608\n",
      "Iteration 25, loss = 82091257522.01258850\n",
      "Validation score: 0.709280\n",
      "Iteration 26, loss = 81399763677.30961609\n",
      "Validation score: 0.709909\n",
      "Iteration 27, loss = 80715884258.08561707\n",
      "Validation score: 0.713171\n",
      "Iteration 28, loss = 80219715443.90966797\n",
      "Validation score: 0.715947\n",
      "Iteration 29, loss = 79582901913.43547058\n",
      "Validation score: 0.717686\n",
      "Iteration 30, loss = 79052083022.48207092\n",
      "Validation score: 0.719297\n",
      "Iteration 31, loss = 78513192514.05236816\n",
      "Validation score: 0.720972\n",
      "Iteration 32, loss = 78033535915.20454407\n",
      "Validation score: 0.722980\n",
      "Iteration 33, loss = 77574734601.24501038\n",
      "Validation score: 0.724913\n",
      "Iteration 34, loss = 77193899084.92541504\n",
      "Validation score: 0.722056\n",
      "Iteration 35, loss = 76807743611.39277649\n",
      "Validation score: 0.727990\n",
      "Iteration 36, loss = 76406778655.35066223\n",
      "Validation score: 0.728682\n",
      "Iteration 37, loss = 76079710101.48449707\n",
      "Validation score: 0.730384\n",
      "Iteration 38, loss = 75637048280.42590332\n",
      "Validation score: 0.730946\n",
      "Iteration 39, loss = 75324739708.97215271\n",
      "Validation score: 0.732570\n",
      "Iteration 40, loss = 75017916693.46124268\n",
      "Validation score: 0.734186\n",
      "Iteration 41, loss = 74784481525.95465088\n",
      "Validation score: 0.734329\n",
      "Iteration 42, loss = 74534521611.92465210\n",
      "Validation score: 0.736171\n",
      "Iteration 43, loss = 74233568414.19161987\n",
      "Validation score: 0.733045\n",
      "Iteration 44, loss = 73988063460.32917786\n",
      "Validation score: 0.736289\n",
      "Iteration 45, loss = 73707085203.56147766\n",
      "Validation score: 0.737242\n",
      "Iteration 46, loss = 73506102459.11300659\n",
      "Validation score: 0.739265\n",
      "Iteration 47, loss = 73294040934.68908691\n",
      "Validation score: 0.740005\n",
      "Iteration 48, loss = 73028324591.86367798\n",
      "Validation score: 0.740229\n",
      "Iteration 49, loss = 72902095202.47019958\n",
      "Validation score: 0.739268\n",
      "Iteration 50, loss = 72705977881.80595398\n",
      "Validation score: 0.741692\n",
      "Iteration 51, loss = 72475348073.46846008\n",
      "Validation score: 0.739002\n",
      "Iteration 52, loss = 72397835831.69740295\n",
      "Validation score: 0.742499\n",
      "Iteration 53, loss = 72179148433.46301270\n",
      "Validation score: 0.742891\n",
      "Iteration 54, loss = 72052488303.73388672\n",
      "Validation score: 0.743270\n",
      "Iteration 55, loss = 71905063287.05563354\n",
      "Validation score: 0.744161\n",
      "Iteration 56, loss = 71775304899.24331665\n",
      "Validation score: 0.743978\n",
      "Iteration 57, loss = 71696429598.54899597\n",
      "Validation score: 0.745398\n",
      "Iteration 58, loss = 71534549844.53614807\n",
      "Validation score: 0.745844\n",
      "Iteration 59, loss = 71468424356.36041260\n",
      "Validation score: 0.744521\n",
      "Iteration 60, loss = 71246596695.47334290\n",
      "Validation score: 0.745298\n",
      "Iteration 61, loss = 71225354752.12017822\n",
      "Validation score: 0.747086\n",
      "Iteration 62, loss = 71069281955.76335144\n",
      "Validation score: 0.743997\n",
      "Iteration 63, loss = 70995044615.48329163\n",
      "Validation score: 0.747494\n",
      "Iteration 64, loss = 70895428275.36451721\n",
      "Validation score: 0.747255\n",
      "Iteration 65, loss = 70799348086.13548279\n",
      "Validation score: 0.747835\n",
      "Iteration 66, loss = 70670320731.46839905\n",
      "Validation score: 0.748235\n",
      "Iteration 67, loss = 70590318801.83064270\n",
      "Validation score: 0.747050\n",
      "Iteration 68, loss = 70600029482.83862305\n",
      "Validation score: 0.748559\n",
      "Iteration 69, loss = 70415255394.58959961\n",
      "Validation score: 0.748984\n",
      "Iteration 70, loss = 70364194658.42015076\n",
      "Validation score: 0.745756\n",
      "Iteration 71, loss = 70304476169.88534546\n",
      "Validation score: 0.749815\n",
      "Iteration 72, loss = 70223510175.61663818\n",
      "Validation score: 0.749515\n",
      "Iteration 73, loss = 70132281051.18040466\n",
      "Validation score: 0.749481\n",
      "Iteration 74, loss = 70046659838.26034546\n",
      "Validation score: 0.749183\n",
      "Iteration 75, loss = 69988725823.76673889\n",
      "Validation score: 0.750363\n",
      "Iteration 76, loss = 69970091497.27091980\n",
      "Validation score: 0.749834\n",
      "Iteration 77, loss = 69821111958.03257751\n",
      "Validation score: 0.749126\n",
      "Iteration 78, loss = 69783861037.39825439\n",
      "Validation score: 0.750359\n",
      "Iteration 79, loss = 69725679055.96376038\n",
      "Validation score: 0.749628\n",
      "Iteration 80, loss = 69709573458.91300964\n",
      "Validation score: 0.751438\n",
      "Iteration 81, loss = 69626606538.79666138\n",
      "Validation score: 0.751553\n",
      "Iteration 82, loss = 69536597376.30255127\n",
      "Validation score: 0.751253\n",
      "Iteration 83, loss = 69563779621.15495300\n",
      "Validation score: 0.752001\n",
      "Iteration 84, loss = 69421141072.87413025\n",
      "Validation score: 0.752104\n",
      "Iteration 85, loss = 69452454069.22663879\n",
      "Validation score: 0.752051\n",
      "Iteration 86, loss = 69316276429.62728882\n",
      "Validation score: 0.751793\n",
      "Iteration 87, loss = 69353300018.99438477\n",
      "Validation score: 0.752470\n",
      "Iteration 88, loss = 69239539811.29100037\n",
      "Validation score: 0.752150\n",
      "Iteration 89, loss = 69191532767.86013794\n",
      "Validation score: 0.752344\n",
      "Iteration 90, loss = 69245916199.58653259\n",
      "Validation score: 0.752537\n",
      "Iteration 91, loss = 69137223928.66064453\n",
      "Validation score: 0.753006\n",
      "Iteration 92, loss = 69144987700.34304810\n",
      "Validation score: 0.753061\n",
      "Iteration 93, loss = 69044808248.87452698\n",
      "Validation score: 0.751448\n",
      "Iteration 94, loss = 68991187829.88449097\n",
      "Validation score: 0.752381\n",
      "Iteration 95, loss = 68959793124.45184326\n",
      "Validation score: 0.753485\n",
      "Iteration 96, loss = 68942467676.12902832\n",
      "Validation score: 0.750661\n",
      "Iteration 97, loss = 68847804711.53120422\n",
      "Validation score: 0.753660\n",
      "Iteration 98, loss = 68841593005.32057190\n",
      "Validation score: 0.752631\n",
      "Iteration 99, loss = 68846275293.90179443\n",
      "Validation score: 0.753419\n",
      "Iteration 100, loss = 68812091892.10620117\n",
      "Validation score: 0.753546\n",
      "Iteration 101, loss = 68698783125.63056946\n",
      "Validation score: 0.753554\n",
      "Iteration 102, loss = 68715065914.15429688\n",
      "Validation score: 0.752982\n",
      "Iteration 103, loss = 68669397691.29160309\n",
      "Validation score: 0.754367\n",
      "Iteration 104, loss = 68672237703.52909088\n",
      "Validation score: 0.754430\n",
      "Iteration 105, loss = 68606635136.58104706\n",
      "Validation score: 0.754598\n",
      "Iteration 106, loss = 68532257352.92692566\n",
      "Validation score: 0.754100\n",
      "Iteration 107, loss = 68501119660.38301086\n",
      "Validation score: 0.754587\n",
      "Iteration 108, loss = 68481713669.49411774\n",
      "Validation score: 0.754117\n",
      "Iteration 109, loss = 68410635208.50376892\n",
      "Validation score: 0.752938\n",
      "Iteration 110, loss = 68498771091.33323669\n",
      "Validation score: 0.754810\n",
      "Iteration 111, loss = 68384507817.36282349\n",
      "Validation score: 0.754869\n",
      "Iteration 112, loss = 68365669083.52214050\n",
      "Validation score: 0.752455\n",
      "Iteration 113, loss = 68340156398.06430817\n",
      "Validation score: 0.754258\n",
      "Iteration 114, loss = 68355638735.63075256\n",
      "Validation score: 0.752217\n",
      "Iteration 115, loss = 68314471286.01731873\n",
      "Validation score: 0.755278\n",
      "Iteration 116, loss = 68194794669.02077484\n",
      "Validation score: 0.755617\n",
      "Iteration 117, loss = 68228304713.29377747\n",
      "Validation score: 0.755629\n",
      "Iteration 118, loss = 68206902164.36140442\n",
      "Validation score: 0.754126\n",
      "Iteration 119, loss = 68207471788.58985138\n",
      "Validation score: 0.755173\n",
      "Iteration 120, loss = 68124628791.81450653\n",
      "Validation score: 0.755836\n",
      "Iteration 121, loss = 68193883474.67307281\n",
      "Validation score: 0.755087\n",
      "Iteration 122, loss = 68098155734.57112122\n",
      "Validation score: 0.755836\n",
      "Iteration 123, loss = 68083318901.82970428\n",
      "Validation score: 0.756105\n",
      "Iteration 124, loss = 68009190891.51754761\n",
      "Validation score: 0.755647\n",
      "Iteration 125, loss = 67960350104.71916962\n",
      "Validation score: 0.746097\n",
      "Iteration 126, loss = 68056049615.61745453\n",
      "Validation score: 0.756228\n",
      "Iteration 127, loss = 67915167034.43118286\n",
      "Validation score: 0.756265\n",
      "Iteration 128, loss = 67909453008.20377350\n",
      "Validation score: 0.756110\n",
      "Iteration 129, loss = 67975112780.24526978\n",
      "Validation score: 0.756421\n",
      "Iteration 130, loss = 67833830610.94612885\n",
      "Validation score: 0.756573\n",
      "Iteration 131, loss = 67856485279.19261932\n",
      "Validation score: 0.756275\n",
      "Iteration 132, loss = 67845334617.78623962\n",
      "Validation score: 0.756692\n",
      "Iteration 133, loss = 67823027314.50559998\n",
      "Validation score: 0.756402\n",
      "Iteration 134, loss = 67800551128.98123932\n",
      "Validation score: 0.756409\n",
      "Iteration 135, loss = 67692953239.29305267\n",
      "Validation score: 0.735385\n",
      "Iteration 136, loss = 68010292053.49398804\n",
      "Validation score: 0.757247\n",
      "Iteration 137, loss = 67732610931.36692810\n",
      "Validation score: 0.757003\n",
      "Iteration 138, loss = 67676113551.48051453\n",
      "Validation score: 0.756771\n",
      "Iteration 139, loss = 67699503511.23695374\n",
      "Validation score: 0.755459\n",
      "Iteration 140, loss = 67687948759.19662476\n",
      "Validation score: 0.757389\n",
      "Iteration 141, loss = 67646568224.08387756\n",
      "Validation score: 0.757278\n",
      "Iteration 142, loss = 67556093600.17016602\n",
      "Validation score: 0.757611\n",
      "Iteration 143, loss = 67604161298.35573578\n",
      "Validation score: 0.754298\n",
      "Iteration 144, loss = 67608763898.93572235\n",
      "Validation score: 0.755971\n",
      "Iteration 145, loss = 67530936583.92656708\n",
      "Validation score: 0.757414\n",
      "Iteration 146, loss = 67499137895.95881653\n",
      "Validation score: 0.753199\n",
      "Iteration 147, loss = 67516341863.19196320\n",
      "Validation score: 0.758096\n",
      "Iteration 148, loss = 67476191588.47521973\n",
      "Validation score: 0.757639\n",
      "Iteration 149, loss = 67432904478.27945709\n",
      "Validation score: 0.758398\n",
      "Iteration 150, loss = 67452421390.89789581\n",
      "Validation score: 0.758346\n",
      "Iteration 151, loss = 67380631549.03802490\n",
      "Validation score: 0.758566\n",
      "Iteration 152, loss = 67323915024.43699646\n",
      "Validation score: 0.758315\n",
      "Iteration 153, loss = 67327532954.39487457\n",
      "Validation score: 0.757972\n",
      "Iteration 154, loss = 67322775103.55480194\n",
      "Validation score: 0.758546\n",
      "Iteration 155, loss = 67219119408.84307098\n",
      "Validation score: 0.758141\n",
      "Iteration 156, loss = 67267796356.68449402\n",
      "Validation score: 0.755354\n",
      "Iteration 157, loss = 67215694758.59423828\n",
      "Validation score: 0.758689\n",
      "Iteration 158, loss = 67162348838.55375671\n",
      "Validation score: 0.758555\n",
      "Iteration 159, loss = 67131923612.77267456\n",
      "Validation score: 0.759327\n",
      "Iteration 160, loss = 67113967184.12955475\n",
      "Validation score: 0.759254\n",
      "Iteration 161, loss = 67033697327.63645935\n",
      "Validation score: 0.758746\n",
      "Iteration 162, loss = 66971602857.66513824\n",
      "Validation score: 0.753753\n",
      "Iteration 163, loss = 66855540520.98773956\n",
      "Validation score: 0.755561\n",
      "Iteration 164, loss = 66962327340.73928070\n",
      "Validation score: 0.759096\n",
      "Iteration 165, loss = 66860707064.54651642\n",
      "Validation score: 0.758963\n",
      "Iteration 166, loss = 66806395553.97498322\n",
      "Validation score: 0.759256\n",
      "Iteration 167, loss = 66746628314.72698212\n",
      "Validation score: 0.759653\n",
      "Iteration 168, loss = 66837226390.38159943\n",
      "Validation score: 0.756958\n",
      "Iteration 169, loss = 66734814474.65972900\n",
      "Validation score: 0.759764\n",
      "Iteration 170, loss = 66698419789.75641632\n",
      "Validation score: 0.753796\n",
      "Iteration 171, loss = 66706993844.53569031\n",
      "Validation score: 0.760284\n",
      "Iteration 172, loss = 66639020555.82106781\n",
      "Validation score: 0.758590\n",
      "Iteration 173, loss = 66615711911.53251648\n",
      "Validation score: 0.759896\n",
      "Iteration 174, loss = 66507591997.21061707\n",
      "Validation score: 0.760443\n",
      "Iteration 175, loss = 66532705685.24304962\n",
      "Validation score: 0.759835\n",
      "Iteration 176, loss = 66537142568.98972321\n",
      "Validation score: 0.755177\n",
      "Iteration 177, loss = 66520971589.73446655\n",
      "Validation score: 0.760449\n",
      "Iteration 178, loss = 66447057120.23563385\n",
      "Validation score: 0.753377\n",
      "Iteration 179, loss = 66439825511.00093079\n",
      "Validation score: 0.758166\n",
      "Iteration 180, loss = 66426420615.63842010\n",
      "Validation score: 0.761256\n",
      "Iteration 181, loss = 66394500421.33683014\n",
      "Validation score: 0.759995\n",
      "Iteration 182, loss = 66347365397.99766541\n",
      "Validation score: 0.753818\n",
      "Iteration 183, loss = 66286870910.55564117\n",
      "Validation score: 0.759505\n",
      "Iteration 184, loss = 66375409765.61677551\n",
      "Validation score: 0.761328\n",
      "Iteration 185, loss = 66259198636.70407867\n",
      "Validation score: 0.761417\n",
      "Iteration 186, loss = 66234281565.62701416\n",
      "Validation score: 0.758400\n",
      "Iteration 187, loss = 66185487677.71158600\n",
      "Validation score: 0.760678\n",
      "Iteration 188, loss = 66132806375.03829193\n",
      "Validation score: 0.761619\n",
      "Iteration 189, loss = 66142081223.78149414\n",
      "Validation score: 0.761199\n",
      "Iteration 190, loss = 66208873787.03368378\n",
      "Validation score: 0.750536\n",
      "Iteration 191, loss = 66113583381.85135651\n",
      "Validation score: 0.761696\n",
      "Iteration 192, loss = 66085238404.05786896\n",
      "Validation score: 0.761699\n",
      "Iteration 193, loss = 66048209268.20378876\n",
      "Validation score: 0.754224\n",
      "Iteration 194, loss = 66067171741.20878601\n",
      "Validation score: 0.762432\n",
      "Iteration 195, loss = 65937439642.05867767\n",
      "Validation score: 0.762051\n",
      "Iteration 196, loss = 65975286376.47717285\n",
      "Validation score: 0.760312\n",
      "Iteration 197, loss = 65906710419.50083160\n",
      "Validation score: 0.762686\n",
      "Iteration 198, loss = 65957233420.99958801\n",
      "Validation score: 0.762438\n",
      "Iteration 199, loss = 65875539867.01623535\n",
      "Validation score: 0.762175\n",
      "Iteration 200, loss = 65854774155.91543579\n",
      "Validation score: 0.760442\n",
      "Iteration 201, loss = 65883177368.02299500\n",
      "Validation score: 0.762621\n",
      "Iteration 202, loss = 65839839064.01281738\n",
      "Validation score: 0.761382\n",
      "Iteration 203, loss = 65740074143.40583038\n",
      "Validation score: 0.761595\n",
      "Iteration 204, loss = 65736785300.51924133\n",
      "Validation score: 0.760852\n",
      "Iteration 205, loss = 65736158038.05627441\n",
      "Validation score: 0.762115\n",
      "Iteration 206, loss = 65751485411.69424438\n",
      "Validation score: 0.763631\n",
      "Iteration 207, loss = 65721744114.83030701\n",
      "Validation score: 0.755526\n",
      "Iteration 208, loss = 65701579106.30619812\n",
      "Validation score: 0.758968\n",
      "Iteration 209, loss = 65672469633.30704498\n",
      "Validation score: 0.748064\n",
      "Iteration 210, loss = 65728928851.05631256\n",
      "Validation score: 0.763948\n",
      "Iteration 211, loss = 65557826340.74069977\n",
      "Validation score: 0.763497\n",
      "Iteration 212, loss = 65602054441.94264984\n",
      "Validation score: 0.763349\n",
      "Iteration 213, loss = 65565191753.40142822\n",
      "Validation score: 0.763346\n",
      "Iteration 214, loss = 65576569776.71014404\n",
      "Validation score: 0.764418\n",
      "Iteration 215, loss = 65481056092.38962555\n",
      "Validation score: 0.759922\n",
      "Iteration 216, loss = 65494877545.17427063\n",
      "Validation score: 0.763810\n",
      "Iteration 217, loss = 65453338283.16067505\n",
      "Validation score: 0.764123\n",
      "Iteration 218, loss = 65500588327.91303253\n",
      "Validation score: 0.764666\n",
      "Iteration 219, loss = 65436092934.96646118\n",
      "Validation score: 0.764100\n",
      "Iteration 220, loss = 65380391948.33589935\n",
      "Validation score: 0.763212\n",
      "Iteration 221, loss = 65398524334.62294769\n",
      "Validation score: 0.759933\n",
      "Iteration 222, loss = 65316705907.39026642\n",
      "Validation score: 0.764550\n",
      "Iteration 223, loss = 65320815756.99379730\n",
      "Validation score: 0.763695\n",
      "Iteration 224, loss = 65381982696.20123291\n",
      "Validation score: 0.763405\n",
      "Iteration 225, loss = 65349174065.77017212\n",
      "Validation score: 0.765362\n",
      "Iteration 226, loss = 65171652182.07088470\n",
      "Validation score: 0.763597\n",
      "Iteration 227, loss = 65215031379.12126923\n",
      "Validation score: 0.762583\n",
      "Iteration 228, loss = 65246999228.13532257\n",
      "Validation score: 0.765377\n",
      "Iteration 229, loss = 65168325176.30564880\n",
      "Validation score: 0.765330\n",
      "Iteration 230, loss = 65225255827.70618439\n",
      "Validation score: 0.764014\n",
      "Iteration 231, loss = 65182733215.10320282\n",
      "Validation score: 0.765745\n",
      "Iteration 232, loss = 65136647321.91276550\n",
      "Validation score: 0.764321\n",
      "Iteration 233, loss = 65082496993.08798981\n",
      "Validation score: 0.766055\n",
      "Iteration 234, loss = 64991627865.44012451\n",
      "Validation score: 0.765246\n",
      "Iteration 235, loss = 65079803279.14373016\n",
      "Validation score: 0.763609\n",
      "Iteration 236, loss = 65091854098.40016937\n",
      "Validation score: 0.763075\n",
      "Iteration 237, loss = 65030798189.56236267\n",
      "Validation score: 0.766107\n",
      "Iteration 238, loss = 64971139910.01262665\n",
      "Validation score: 0.766094\n",
      "Iteration 239, loss = 65013209458.98650360\n",
      "Validation score: 0.766453\n",
      "Iteration 240, loss = 64914093681.88009644\n",
      "Validation score: 0.766164\n",
      "Iteration 241, loss = 64977262252.12122345\n",
      "Validation score: 0.766254\n",
      "Iteration 242, loss = 65013047004.47978973\n",
      "Validation score: 0.766220\n",
      "Iteration 243, loss = 64925600166.32595062\n",
      "Validation score: 0.762860\n",
      "Iteration 244, loss = 64990751494.91448212\n",
      "Validation score: 0.762993\n",
      "Iteration 245, loss = 64792999314.69364166\n",
      "Validation score: 0.765699\n",
      "Iteration 246, loss = 64766318497.71821594\n",
      "Validation score: 0.766731\n",
      "Iteration 247, loss = 64808252564.01081848\n",
      "Validation score: 0.760990\n",
      "Iteration 248, loss = 64858654785.90329742\n",
      "Validation score: 0.767060\n",
      "Iteration 249, loss = 64759232572.15711212\n",
      "Validation score: 0.758763\n",
      "Iteration 250, loss = 64714929304.35585022\n",
      "Validation score: 0.766991\n",
      "Iteration 251, loss = 64684912055.03456116\n",
      "Validation score: 0.767388\n",
      "Iteration 252, loss = 64735032661.33981323\n",
      "Validation score: 0.766038\n",
      "Iteration 253, loss = 64699601982.08900452\n",
      "Validation score: 0.767589\n",
      "Iteration 254, loss = 64629084550.65303802\n",
      "Validation score: 0.767572\n",
      "Iteration 255, loss = 64656844715.85993195\n",
      "Validation score: 0.767826\n",
      "Iteration 256, loss = 64646706041.03648376\n",
      "Validation score: 0.767749\n",
      "Iteration 257, loss = 64686189970.42041016\n",
      "Validation score: 0.767311\n",
      "Iteration 258, loss = 64651846453.30533600\n",
      "Validation score: 0.767895\n",
      "Iteration 259, loss = 64576574105.66028595\n",
      "Validation score: 0.767920\n",
      "Iteration 260, loss = 64565865466.68035889\n",
      "Validation score: 0.762139\n",
      "Iteration 261, loss = 64572903338.47604370\n",
      "Validation score: 0.766094\n",
      "Iteration 262, loss = 64532839848.76446533\n",
      "Validation score: 0.764163\n",
      "Iteration 263, loss = 64454352373.59969330\n",
      "Validation score: 0.765358\n",
      "Iteration 264, loss = 64409925836.44435883\n",
      "Validation score: 0.768552\n",
      "Iteration 265, loss = 64464770669.84649658\n",
      "Validation score: 0.767616\n",
      "Iteration 266, loss = 64424063969.46771240\n",
      "Validation score: 0.767565\n",
      "Iteration 267, loss = 64430775781.17517853\n",
      "Validation score: 0.767146\n",
      "Iteration 268, loss = 64371363482.26940155\n",
      "Validation score: 0.768277\n",
      "Iteration 269, loss = 64397078966.61881256\n",
      "Validation score: 0.768943\n",
      "Iteration 270, loss = 64416781903.54701996\n",
      "Validation score: 0.761929\n",
      "Iteration 271, loss = 64346097094.59229279\n",
      "Validation score: 0.769119\n",
      "Iteration 272, loss = 64339853107.94148254\n",
      "Validation score: 0.767278\n",
      "Iteration 273, loss = 64328914249.53913116\n",
      "Validation score: 0.768976\n",
      "Iteration 274, loss = 64278529159.41867065\n",
      "Validation score: 0.769297\n",
      "Iteration 275, loss = 64219998106.18725586\n",
      "Validation score: 0.768419\n",
      "Iteration 276, loss = 64217231342.27058411\n",
      "Validation score: 0.767917\n",
      "Iteration 277, loss = 64204089157.58778381\n",
      "Validation score: 0.768656\n",
      "Iteration 278, loss = 64175872549.18216705\n",
      "Validation score: 0.767600\n",
      "Iteration 279, loss = 64207155915.97557068\n",
      "Validation score: 0.768055\n",
      "Iteration 280, loss = 64163196577.17713928\n",
      "Validation score: 0.767189\n",
      "Iteration 281, loss = 64137212872.12700653\n",
      "Validation score: 0.765218\n",
      "Iteration 282, loss = 64137528601.93927002\n",
      "Validation score: 0.769555\n",
      "Iteration 283, loss = 64078687191.53953552\n",
      "Validation score: 0.769378\n",
      "Iteration 284, loss = 64203472390.84573364\n",
      "Validation score: 0.768376\n",
      "Iteration 285, loss = 64055383849.96030426\n",
      "Validation score: 0.769112\n",
      "Iteration 286, loss = 64030316044.88564301\n",
      "Validation score: 0.769367\n",
      "Iteration 287, loss = 63968652119.20407104\n",
      "Validation score: 0.770173\n",
      "Iteration 288, loss = 64091806977.69091034\n",
      "Validation score: 0.769995\n",
      "Iteration 289, loss = 63960832056.61946869\n",
      "Validation score: 0.770167\n",
      "Iteration 290, loss = 63948043050.24568939\n",
      "Validation score: 0.770049\n",
      "Iteration 291, loss = 63913778116.20872498\n",
      "Validation score: 0.769260\n",
      "Iteration 292, loss = 63946011243.37377167\n",
      "Validation score: 0.770354\n",
      "Iteration 293, loss = 63894305918.34320831\n",
      "Validation score: 0.769656\n",
      "Iteration 294, loss = 63793413212.46024323\n",
      "Validation score: 0.769192\n",
      "Iteration 295, loss = 63858416158.63700104\n",
      "Validation score: 0.766835\n",
      "Iteration 296, loss = 63839259236.87655640\n",
      "Validation score: 0.770522\n",
      "Iteration 297, loss = 63679882823.32434845\n",
      "Validation score: 0.767375\n",
      "Iteration 298, loss = 63749852699.09958649\n",
      "Validation score: 0.769764\n",
      "Iteration 299, loss = 63763073121.22420502\n",
      "Validation score: 0.766849\n",
      "Iteration 300, loss = 63750984400.56757355\n",
      "Validation score: 0.766412\n",
      "Iteration 301, loss = 63719220232.80204773\n",
      "Validation score: 0.768797\n",
      "Iteration 302, loss = 63675785497.76959991\n",
      "Validation score: 0.768983\n",
      "Iteration 303, loss = 63665654454.31561279\n",
      "Validation score: 0.771268\n",
      "Iteration 304, loss = 63581926436.88495636\n",
      "Validation score: 0.770713\n",
      "Iteration 305, loss = 63546429630.39098358\n",
      "Validation score: 0.768579\n",
      "Iteration 306, loss = 63702539003.90433502\n",
      "Validation score: 0.769887\n",
      "Iteration 307, loss = 63534128463.16185760\n",
      "Validation score: 0.768351\n",
      "Iteration 308, loss = 63631032009.66417694\n",
      "Validation score: 0.770229\n",
      "Iteration 309, loss = 63509988383.76818085\n",
      "Validation score: 0.769059\n",
      "Iteration 310, loss = 63459265439.05458069\n",
      "Validation score: 0.769742\n",
      "Iteration 311, loss = 63512961907.36952209\n",
      "Validation score: 0.769668\n",
      "Iteration 312, loss = 63519220896.53322601\n",
      "Validation score: 0.771022\n",
      "Iteration 313, loss = 63443645143.00818634\n",
      "Validation score: 0.770878\n",
      "Iteration 314, loss = 63383155568.21113586\n",
      "Validation score: 0.769915\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.6884586646109039, 0.5351553471140977\n",
      "Processing feature set: finance_only\n",
      "Iteration 1, loss = 279104182343.93688965\n",
      "Validation score: 0.201886\n",
      "Iteration 2, loss = 215698588282.02597046\n",
      "Validation score: 0.326717\n",
      "Iteration 3, loss = 174186690103.40197754\n",
      "Validation score: 0.483957\n",
      "Iteration 4, loss = 139838715501.08142090\n",
      "Validation score: 0.584881\n",
      "Iteration 5, loss = 120323817917.51800537\n",
      "Validation score: 0.634801\n",
      "Iteration 6, loss = 110850888824.43092346\n",
      "Validation score: 0.657648\n",
      "Iteration 7, loss = 105916350426.84057617\n",
      "Validation score: 0.669015\n",
      "Iteration 8, loss = 102577915818.70521545\n",
      "Validation score: 0.681570\n",
      "Iteration 9, loss = 99785858824.15031433\n",
      "Validation score: 0.691316\n",
      "Iteration 10, loss = 97740880663.66174316\n",
      "Validation score: 0.693881\n",
      "Iteration 11, loss = 95969755721.15225220\n",
      "Validation score: 0.696570\n",
      "Iteration 12, loss = 94235068580.08253479\n",
      "Validation score: 0.706830\n",
      "Iteration 13, loss = 92724597159.48255920\n",
      "Validation score: 0.706250\n",
      "Iteration 14, loss = 91114259535.61294556\n",
      "Validation score: 0.713757\n",
      "Iteration 15, loss = 89920951785.61135864\n",
      "Validation score: 0.718680\n",
      "Iteration 16, loss = 88904376255.33457947\n",
      "Validation score: 0.721827\n",
      "Iteration 17, loss = 87527220131.57708740\n",
      "Validation score: 0.725514\n",
      "Iteration 18, loss = 86468303939.90942383\n",
      "Validation score: 0.721408\n",
      "Iteration 19, loss = 85724668299.63633728\n",
      "Validation score: 0.729221\n",
      "Iteration 20, loss = 84746269767.35961914\n",
      "Validation score: 0.731133\n",
      "Iteration 21, loss = 83792495300.30227661\n",
      "Validation score: 0.733691\n",
      "Iteration 22, loss = 83030367873.27523804\n",
      "Validation score: 0.732648\n",
      "Iteration 23, loss = 82246873553.45930481\n",
      "Validation score: 0.739730\n",
      "Iteration 24, loss = 81653302793.71650696\n",
      "Validation score: 0.741712\n",
      "Iteration 25, loss = 80802118875.59808350\n",
      "Validation score: 0.737637\n",
      "Iteration 26, loss = 80564622141.84611511\n",
      "Validation score: 0.742213\n",
      "Iteration 27, loss = 79610515956.50898743\n",
      "Validation score: 0.730793\n",
      "Iteration 28, loss = 79132292612.99452209\n",
      "Validation score: 0.748590\n",
      "Iteration 29, loss = 78664362601.04919434\n",
      "Validation score: 0.744167\n",
      "Iteration 30, loss = 78112180025.56407166\n",
      "Validation score: 0.751829\n",
      "Iteration 31, loss = 77561915739.07623291\n",
      "Validation score: 0.747207\n",
      "Iteration 32, loss = 77182684728.73081970\n",
      "Validation score: 0.744666\n",
      "Iteration 33, loss = 76955192939.39633179\n",
      "Validation score: 0.752228\n",
      "Iteration 34, loss = 76567550004.56062317\n",
      "Validation score: 0.753250\n",
      "Iteration 35, loss = 76121219289.36563110\n",
      "Validation score: 0.756438\n",
      "Iteration 36, loss = 75797157157.63955688\n",
      "Validation score: 0.753126\n",
      "Iteration 37, loss = 75384885951.52629089\n",
      "Validation score: 0.754657\n",
      "Iteration 38, loss = 75087712101.06394958\n",
      "Validation score: 0.755991\n",
      "Iteration 39, loss = 74625435780.84466553\n",
      "Validation score: 0.746448\n",
      "Iteration 40, loss = 74202178494.27932739\n",
      "Validation score: 0.744156\n",
      "Iteration 41, loss = 74046435163.82838440\n",
      "Validation score: 0.761687\n",
      "Iteration 42, loss = 73761192267.62034607\n",
      "Validation score: 0.763866\n",
      "Iteration 43, loss = 73382772917.34838867\n",
      "Validation score: 0.743673\n",
      "Iteration 44, loss = 73132794902.94111633\n",
      "Validation score: 0.764213\n",
      "Iteration 45, loss = 73204637725.38008118\n",
      "Validation score: 0.764254\n",
      "Iteration 46, loss = 72792847530.41630554\n",
      "Validation score: 0.764794\n",
      "Iteration 47, loss = 72647651629.94535828\n",
      "Validation score: 0.766344\n",
      "Iteration 48, loss = 72545921877.59904480\n",
      "Validation score: 0.766631\n",
      "Iteration 49, loss = 72123003722.33471680\n",
      "Validation score: 0.761130\n",
      "Iteration 50, loss = 71951598565.87693787\n",
      "Validation score: 0.765505\n",
      "Iteration 51, loss = 71891941850.68124390\n",
      "Validation score: 0.767971\n",
      "Iteration 52, loss = 71381941072.16575623\n",
      "Validation score: 0.768170\n",
      "Iteration 53, loss = 71216929542.33473206\n",
      "Validation score: 0.770270\n",
      "Iteration 54, loss = 71372731007.19927979\n",
      "Validation score: 0.766092\n",
      "Iteration 55, loss = 70831783080.48417664\n",
      "Validation score: 0.769525\n",
      "Iteration 56, loss = 71075665139.29368591\n",
      "Validation score: 0.771745\n",
      "Iteration 57, loss = 70767572306.95840454\n",
      "Validation score: 0.766742\n",
      "Iteration 58, loss = 70498429999.06576538\n",
      "Validation score: 0.772406\n",
      "Iteration 59, loss = 70397443730.55375671\n",
      "Validation score: 0.771891\n",
      "Iteration 60, loss = 70425607155.66366577\n",
      "Validation score: 0.769414\n",
      "Iteration 61, loss = 70115850368.27296448\n",
      "Validation score: 0.773437\n",
      "Iteration 62, loss = 69959645360.84822083\n",
      "Validation score: 0.686848\n",
      "Iteration 63, loss = 70405439454.27288818\n",
      "Validation score: 0.764880\n",
      "Iteration 64, loss = 69563838907.12847900\n",
      "Validation score: 0.770801\n",
      "Iteration 65, loss = 69727177491.35920715\n",
      "Validation score: 0.775371\n",
      "Iteration 66, loss = 69351816280.83715820\n",
      "Validation score: 0.775755\n",
      "Iteration 67, loss = 69389334961.47471619\n",
      "Validation score: 0.737457\n",
      "Iteration 68, loss = 69338730669.55638123\n",
      "Validation score: 0.765763\n",
      "Iteration 69, loss = 69136017701.10125732\n",
      "Validation score: 0.773748\n",
      "Iteration 70, loss = 69173191778.62940979\n",
      "Validation score: 0.774934\n",
      "Iteration 71, loss = 68844669578.75144958\n",
      "Validation score: 0.777057\n",
      "Iteration 72, loss = 68972317254.49359131\n",
      "Validation score: 0.761606\n",
      "Iteration 73, loss = 69009370901.79244995\n",
      "Validation score: 0.774087\n",
      "Iteration 74, loss = 68532830039.89735413\n",
      "Validation score: 0.779045\n",
      "Iteration 75, loss = 68644771290.09541321\n",
      "Validation score: 0.779669\n",
      "Iteration 76, loss = 68255516419.47361755\n",
      "Validation score: 0.775259\n",
      "Iteration 77, loss = 68463092949.60826874\n",
      "Validation score: 0.773968\n",
      "Iteration 78, loss = 68045514199.72025299\n",
      "Validation score: 0.779942\n",
      "Iteration 79, loss = 67852144546.95515442\n",
      "Validation score: 0.761971\n",
      "Iteration 80, loss = 68094302941.07835388\n",
      "Validation score: 0.780391\n",
      "Iteration 81, loss = 67793864862.05956268\n",
      "Validation score: 0.775425\n",
      "Iteration 82, loss = 67789927268.25220490\n",
      "Validation score: 0.779875\n",
      "Iteration 83, loss = 67462567095.81773376\n",
      "Validation score: 0.781595\n",
      "Iteration 84, loss = 67780510419.36730957\n",
      "Validation score: 0.779934\n",
      "Iteration 85, loss = 67604173536.74684906\n",
      "Validation score: 0.782500\n",
      "Iteration 86, loss = 67174715730.70452118\n",
      "Validation score: 0.778869\n",
      "Iteration 87, loss = 67515291528.01078796\n",
      "Validation score: 0.782336\n",
      "Iteration 88, loss = 67235083891.99147034\n",
      "Validation score: 0.781924\n",
      "Iteration 89, loss = 67286755794.97248077\n",
      "Validation score: 0.780499\n",
      "Iteration 90, loss = 66881079790.88923645\n",
      "Validation score: 0.782569\n",
      "Iteration 91, loss = 67057991410.91575623\n",
      "Validation score: 0.779679\n",
      "Iteration 92, loss = 66555267055.86606598\n",
      "Validation score: 0.781033\n",
      "Iteration 93, loss = 66971809872.78256989\n",
      "Validation score: 0.780721\n",
      "Iteration 94, loss = 66650055240.25148010\n",
      "Validation score: 0.780949\n",
      "Iteration 95, loss = 66664045682.97757721\n",
      "Validation score: 0.784346\n",
      "Iteration 96, loss = 66375836923.52884674\n",
      "Validation score: 0.784654\n",
      "Iteration 97, loss = 66543722979.08822632\n",
      "Validation score: 0.785335\n",
      "Iteration 98, loss = 66638358885.91864014\n",
      "Validation score: 0.780145\n",
      "Iteration 99, loss = 65958267270.86888123\n",
      "Validation score: 0.781644\n",
      "Iteration 100, loss = 66348051805.96502686\n",
      "Validation score: 0.783890\n",
      "Iteration 101, loss = 66138858488.62480164\n",
      "Validation score: 0.764747\n",
      "Iteration 102, loss = 65940769399.77032471\n",
      "Validation score: 0.630820\n",
      "Iteration 103, loss = 66787729811.78182220\n",
      "Validation score: 0.785335\n",
      "Iteration 104, loss = 65760465182.78511047\n",
      "Validation score: 0.784268\n",
      "Iteration 105, loss = 65744526293.96130371\n",
      "Validation score: 0.784944\n",
      "Iteration 106, loss = 65657757962.39096069\n",
      "Validation score: 0.785222\n",
      "Iteration 107, loss = 65809030635.11112976\n",
      "Validation score: 0.782413\n",
      "Iteration 108, loss = 65725993141.65830994\n",
      "Validation score: 0.782304\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.6531915869650469, 0.5221022333170084\n",
      "Processing feature set: finance_time\n",
      "Iteration 1, loss = 277558425422.30670166\n",
      "Validation score: 0.254110\n",
      "Iteration 2, loss = 194800425715.15063477\n",
      "Validation score: 0.468118\n",
      "Iteration 3, loss = 143527085648.51748657\n",
      "Validation score: 0.597983\n",
      "Iteration 4, loss = 116968342094.18690491\n",
      "Validation score: 0.658625\n",
      "Iteration 5, loss = 103951727511.13563538\n",
      "Validation score: 0.693170\n",
      "Iteration 6, loss = 97043214654.92210388\n",
      "Validation score: 0.712301\n",
      "Iteration 7, loss = 92624094388.43019104\n",
      "Validation score: 0.725528\n",
      "Iteration 8, loss = 89414750177.06373596\n",
      "Validation score: 0.717845\n",
      "Iteration 9, loss = 87171086121.22547913\n",
      "Validation score: 0.742855\n",
      "Iteration 10, loss = 85283796452.05694580\n",
      "Validation score: 0.745498\n",
      "Iteration 11, loss = 83607401145.14120483\n",
      "Validation score: 0.752230\n",
      "Iteration 12, loss = 82229274180.84886169\n",
      "Validation score: 0.757487\n",
      "Iteration 13, loss = 80660805118.87619019\n",
      "Validation score: 0.761092\n",
      "Iteration 14, loss = 79392330889.07398987\n",
      "Validation score: 0.762563\n",
      "Iteration 15, loss = 78497624849.12496948\n",
      "Validation score: 0.766345\n",
      "Iteration 16, loss = 77338323016.19445801\n",
      "Validation score: 0.771363\n",
      "Iteration 17, loss = 76576051470.05960083\n",
      "Validation score: 0.772603\n",
      "Iteration 18, loss = 75681422294.49084473\n",
      "Validation score: 0.776527\n",
      "Iteration 19, loss = 74596439890.60049438\n",
      "Validation score: 0.776678\n",
      "Iteration 20, loss = 73967623903.70552063\n",
      "Validation score: 0.775654\n",
      "Iteration 21, loss = 73077362491.97363281\n",
      "Validation score: 0.783181\n",
      "Iteration 22, loss = 72323162386.95683289\n",
      "Validation score: 0.785328\n",
      "Iteration 23, loss = 71731204159.87269592\n",
      "Validation score: 0.779456\n",
      "Iteration 24, loss = 71124906690.64620972\n",
      "Validation score: 0.786761\n",
      "Iteration 25, loss = 70613453217.10557556\n",
      "Validation score: 0.788495\n",
      "Iteration 26, loss = 70133321190.84326172\n",
      "Validation score: 0.792289\n",
      "Iteration 27, loss = 69470948559.61882019\n",
      "Validation score: 0.786438\n",
      "Iteration 28, loss = 68922329969.46479797\n",
      "Validation score: 0.672022\n",
      "Iteration 29, loss = 69197809452.40859985\n",
      "Validation score: 0.786711\n",
      "Iteration 30, loss = 68313806162.33092499\n",
      "Validation score: 0.794538\n",
      "Iteration 31, loss = 67881120813.43675995\n",
      "Validation score: 0.795493\n",
      "Iteration 32, loss = 67974811145.49386597\n",
      "Validation score: 0.794570\n",
      "Iteration 33, loss = 67209518139.94886017\n",
      "Validation score: 0.798312\n",
      "Iteration 34, loss = 66600719591.05606079\n",
      "Validation score: 0.798467\n",
      "Iteration 35, loss = 66565415520.37196350\n",
      "Validation score: 0.801689\n",
      "Iteration 36, loss = 66241045898.81899261\n",
      "Validation score: 0.794237\n",
      "Iteration 37, loss = 65847819360.24085999\n",
      "Validation score: 0.802001\n",
      "Iteration 38, loss = 65766000092.50016785\n",
      "Validation score: 0.801339\n",
      "Iteration 39, loss = 65268351604.10063934\n",
      "Validation score: 0.803348\n",
      "Iteration 40, loss = 65110022165.74604034\n",
      "Validation score: 0.797383\n",
      "Iteration 41, loss = 64694258764.98710632\n",
      "Validation score: 0.800748\n",
      "Iteration 42, loss = 64633818031.77222443\n",
      "Validation score: 0.803158\n",
      "Iteration 43, loss = 64394095551.89569092\n",
      "Validation score: 0.801411\n",
      "Iteration 44, loss = 64312311076.05427551\n",
      "Validation score: 0.807037\n",
      "Iteration 45, loss = 63997991983.45061493\n",
      "Validation score: 0.805239\n",
      "Iteration 46, loss = 63555758800.18016052\n",
      "Validation score: 0.807946\n",
      "Iteration 47, loss = 63472924715.94638062\n",
      "Validation score: 0.806786\n",
      "Iteration 48, loss = 63173446289.16519165\n",
      "Validation score: 0.798920\n",
      "Iteration 49, loss = 63051451070.71866608\n",
      "Validation score: 0.809341\n",
      "Iteration 50, loss = 62827304542.65161896\n",
      "Validation score: 0.805807\n",
      "Iteration 51, loss = 62997810273.96230316\n",
      "Validation score: 0.810041\n",
      "Iteration 52, loss = 62317861171.19545746\n",
      "Validation score: 0.804045\n",
      "Iteration 53, loss = 62131092470.14816284\n",
      "Validation score: 0.811044\n",
      "Iteration 54, loss = 62234247908.68802643\n",
      "Validation score: 0.811499\n",
      "Iteration 55, loss = 61958288094.63264465\n",
      "Validation score: 0.792581\n",
      "Iteration 56, loss = 61770382701.31751251\n",
      "Validation score: 0.808445\n",
      "Iteration 57, loss = 62009911620.75816345\n",
      "Validation score: 0.812060\n",
      "Iteration 58, loss = 61434392651.45672607\n",
      "Validation score: 0.807347\n",
      "Iteration 59, loss = 61360910346.75111389\n",
      "Validation score: 0.798847\n",
      "Iteration 60, loss = 61316703973.98385620\n",
      "Validation score: 0.795392\n",
      "Iteration 61, loss = 60895203745.08889008\n",
      "Validation score: 0.808568\n",
      "Iteration 62, loss = 60937709182.12300110\n",
      "Validation score: 0.803542\n",
      "Iteration 63, loss = 60641847180.95053101\n",
      "Validation score: 0.793015\n",
      "Iteration 64, loss = 62052687672.50554657\n",
      "Validation score: 0.799959\n",
      "Iteration 65, loss = 60689044861.22419739\n",
      "Validation score: 0.805359\n",
      "Iteration 66, loss = 60045273529.97939301\n",
      "Validation score: 0.800287\n",
      "Iteration 67, loss = 60148195949.60575867\n",
      "Validation score: 0.812299\n",
      "Iteration 68, loss = 59949067870.28386688\n",
      "Validation score: 0.813800\n",
      "Iteration 69, loss = 59800451025.44638062\n",
      "Validation score: 0.815954\n",
      "Iteration 70, loss = 59683405618.84938049\n",
      "Validation score: 0.812852\n",
      "Iteration 71, loss = 59222952523.71921539\n",
      "Validation score: 0.813731\n",
      "Iteration 72, loss = 59144452295.83548737\n",
      "Validation score: 0.812832\n",
      "Iteration 73, loss = 59025018082.64028931\n",
      "Validation score: 0.818775\n",
      "Iteration 74, loss = 58810928854.13163757\n",
      "Validation score: 0.818217\n",
      "Iteration 75, loss = 58670235708.58274841\n",
      "Validation score: 0.820015\n",
      "Iteration 76, loss = 58521340986.47372437\n",
      "Validation score: 0.815744\n",
      "Iteration 77, loss = 58380870986.37718964\n",
      "Validation score: 0.817558\n",
      "Iteration 78, loss = 58157634169.35223389\n",
      "Validation score: 0.820990\n",
      "Iteration 79, loss = 57767487498.51182556\n",
      "Validation score: 0.816406\n",
      "Iteration 80, loss = 57772881305.19919586\n",
      "Validation score: 0.811706\n",
      "Iteration 81, loss = 57911610664.48533630\n",
      "Validation score: 0.814935\n",
      "Iteration 82, loss = 57753176357.06120300\n",
      "Validation score: 0.821316\n",
      "Iteration 83, loss = 57314341945.66681671\n",
      "Validation score: 0.817903\n",
      "Iteration 84, loss = 57387158681.55596161\n",
      "Validation score: 0.818233\n",
      "Iteration 85, loss = 57028616531.37313843\n",
      "Validation score: 0.800883\n",
      "Iteration 86, loss = 57125389093.34809113\n",
      "Validation score: 0.818127\n",
      "Iteration 87, loss = 56796900977.67720795\n",
      "Validation score: 0.814844\n",
      "Iteration 88, loss = 57022255133.91204071\n",
      "Validation score: 0.798772\n",
      "Iteration 89, loss = 57155588281.30169678\n",
      "Validation score: 0.819891\n",
      "Iteration 90, loss = 56483444054.02281952\n",
      "Validation score: 0.824120\n",
      "Iteration 91, loss = 56576415332.74785614\n",
      "Validation score: 0.819260\n",
      "Iteration 92, loss = 56516074387.17361450\n",
      "Validation score: 0.817908\n",
      "Iteration 93, loss = 56250771179.71867371\n",
      "Validation score: 0.821621\n",
      "Iteration 94, loss = 56229115183.04325104\n",
      "Validation score: 0.823132\n",
      "Iteration 95, loss = 56138069844.87441254\n",
      "Validation score: 0.824118\n",
      "Iteration 96, loss = 56147652075.18687439\n",
      "Validation score: 0.823675\n",
      "Iteration 97, loss = 56026604121.57447815\n",
      "Validation score: 0.826097\n",
      "Iteration 98, loss = 55830395383.10655975\n",
      "Validation score: 0.826328\n",
      "Iteration 99, loss = 55735840682.65726471\n",
      "Validation score: 0.823590\n",
      "Iteration 100, loss = 55705447256.68936920\n",
      "Validation score: 0.823371\n",
      "Iteration 101, loss = 55534381159.07800293\n",
      "Validation score: 0.822823\n",
      "Iteration 102, loss = 55533243843.88635254\n",
      "Validation score: 0.822191\n",
      "Iteration 103, loss = 55596164480.14484406\n",
      "Validation score: 0.814435\n",
      "Iteration 104, loss = 55198962490.43872833\n",
      "Validation score: 0.824681\n",
      "Iteration 105, loss = 54904713449.56710052\n",
      "Validation score: 0.822837\n",
      "Iteration 106, loss = 55345474581.38329315\n",
      "Validation score: 0.824435\n",
      "Iteration 107, loss = 55050803844.52500153\n",
      "Validation score: 0.822155\n",
      "Iteration 108, loss = 54901255683.46367645\n",
      "Validation score: 0.813300\n",
      "Iteration 109, loss = 54393251473.08021545\n",
      "Validation score: 0.802359\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.7232303156823392, 0.5902265973355048\n",
      "Processing feature set: all\n",
      "Iteration 1, loss = 260054422124.48248291\n",
      "Validation score: 0.276278\n",
      "Iteration 2, loss = 178614368626.65319824\n",
      "Validation score: 0.395876\n",
      "Iteration 3, loss = 143915181230.47857666\n",
      "Validation score: 0.483411\n",
      "Iteration 4, loss = 121111209166.24615479\n",
      "Validation score: 0.532148\n",
      "Iteration 5, loss = 108184015032.93757629\n",
      "Validation score: 0.555474\n",
      "Iteration 6, loss = 100378811381.48416138\n",
      "Validation score: 0.580932\n",
      "Iteration 7, loss = 94862926346.83290100\n",
      "Validation score: 0.593313\n",
      "Iteration 8, loss = 90705377206.99890137\n",
      "Validation score: 0.605831\n",
      "Iteration 9, loss = 87185543557.20108032\n",
      "Validation score: 0.608582\n",
      "Iteration 10, loss = 84420996891.25683594\n",
      "Validation score: 0.623861\n",
      "Iteration 11, loss = 81489919606.11003113\n",
      "Validation score: 0.631379\n",
      "Iteration 12, loss = 79490591098.73408508\n",
      "Validation score: 0.637590\n",
      "Iteration 13, loss = 77610295767.26731873\n",
      "Validation score: 0.643521\n",
      "Iteration 14, loss = 75789431047.23446655\n",
      "Validation score: 0.648101\n",
      "Iteration 15, loss = 74149840400.85681152\n",
      "Validation score: 0.651831\n",
      "Iteration 16, loss = 72701244492.30680847\n",
      "Validation score: 0.658602\n",
      "Iteration 17, loss = 71075674150.70155334\n",
      "Validation score: 0.652871\n",
      "Iteration 18, loss = 70030249531.92820740\n",
      "Validation score: 0.667028\n",
      "Iteration 19, loss = 68807463013.74517822\n",
      "Validation score: 0.670372\n",
      "Iteration 20, loss = 67424811162.43624115\n",
      "Validation score: 0.672179\n",
      "Iteration 21, loss = 66532299547.62973785\n",
      "Validation score: 0.676949\n",
      "Iteration 22, loss = 65321072956.96041870\n",
      "Validation score: 0.678849\n",
      "Iteration 23, loss = 64812160763.77278137\n",
      "Validation score: 0.680931\n",
      "Iteration 24, loss = 64023279819.49156952\n",
      "Validation score: 0.683800\n",
      "Iteration 25, loss = 63171063072.95609283\n",
      "Validation score: 0.686609\n",
      "Iteration 26, loss = 62676953913.10142517\n",
      "Validation score: 0.687970\n",
      "Iteration 27, loss = 61851412425.40689850\n",
      "Validation score: 0.687035\n",
      "Iteration 28, loss = 61526323978.52485657\n",
      "Validation score: 0.682366\n",
      "Iteration 29, loss = 61070125587.18727112\n",
      "Validation score: 0.690931\n",
      "Iteration 30, loss = 60584747521.69836426\n",
      "Validation score: 0.676594\n",
      "Iteration 31, loss = 60143211350.04137421\n",
      "Validation score: 0.693430\n",
      "Iteration 32, loss = 59646553513.80653381\n",
      "Validation score: 0.695179\n",
      "Iteration 33, loss = 59377863151.55181122\n",
      "Validation score: 0.657492\n",
      "Iteration 34, loss = 59586812541.75869751\n",
      "Validation score: 0.698751\n",
      "Iteration 35, loss = 58312728591.30246735\n",
      "Validation score: 0.699572\n",
      "Iteration 36, loss = 58381696408.87092590\n",
      "Validation score: 0.699780\n",
      "Iteration 37, loss = 58030041773.49568176\n",
      "Validation score: 0.700955\n",
      "Iteration 38, loss = 57427638728.90820312\n",
      "Validation score: 0.700966\n",
      "Iteration 39, loss = 57299033460.40413666\n",
      "Validation score: 0.698042\n",
      "Iteration 40, loss = 57191248887.10789490\n",
      "Validation score: 0.700741\n",
      "Iteration 41, loss = 56892041477.76321411\n",
      "Validation score: 0.703102\n",
      "Iteration 42, loss = 56515711447.76341248\n",
      "Validation score: 0.695770\n",
      "Iteration 43, loss = 56406753927.32975769\n",
      "Validation score: 0.696115\n",
      "Iteration 44, loss = 55971486311.46498108\n",
      "Validation score: 0.707269\n",
      "Iteration 45, loss = 55735236827.61890411\n",
      "Validation score: 0.705893\n",
      "Iteration 46, loss = 55390790932.19906616\n",
      "Validation score: 0.703745\n",
      "Iteration 47, loss = 55227871924.89078522\n",
      "Validation score: 0.706870\n",
      "Iteration 48, loss = 55050800960.91871643\n",
      "Validation score: 0.701157\n",
      "Iteration 49, loss = 54745761126.99825287\n",
      "Validation score: 0.709180\n",
      "Iteration 50, loss = 54489412508.49005127\n",
      "Validation score: 0.710469\n",
      "Iteration 51, loss = 54593036477.26953888\n",
      "Validation score: 0.709075\n",
      "Iteration 52, loss = 54156459229.71026611\n",
      "Validation score: 0.710007\n",
      "Iteration 53, loss = 54090685249.77387238\n",
      "Validation score: 0.708197\n",
      "Iteration 54, loss = 53742489298.06221771\n",
      "Validation score: 0.698189\n",
      "Iteration 55, loss = 54011245124.30681610\n",
      "Validation score: 0.711739\n",
      "Iteration 56, loss = 53858679558.13662720\n",
      "Validation score: 0.710046\n",
      "Iteration 57, loss = 53520091951.69115448\n",
      "Validation score: 0.709837\n",
      "Iteration 58, loss = 53188120973.93968964\n",
      "Validation score: 0.716597\n",
      "Iteration 59, loss = 53241295367.62549591\n",
      "Validation score: 0.715161\n",
      "Iteration 60, loss = 52851306897.66898346\n",
      "Validation score: 0.712499\n",
      "Iteration 61, loss = 52734758211.93455505\n",
      "Validation score: 0.711904\n",
      "Iteration 62, loss = 52334017200.62329102\n",
      "Validation score: 0.717121\n",
      "Iteration 63, loss = 52254496421.37149048\n",
      "Validation score: 0.710139\n",
      "Iteration 64, loss = 52221305119.90179443\n",
      "Validation score: 0.715877\n",
      "Iteration 65, loss = 52023778556.97378540\n",
      "Validation score: 0.714405\n",
      "Iteration 66, loss = 51776708448.33893585\n",
      "Validation score: 0.719946\n",
      "Iteration 67, loss = 51727632646.46791077\n",
      "Validation score: 0.719674\n",
      "Iteration 68, loss = 51586714919.44711304\n",
      "Validation score: 0.718766\n",
      "Iteration 69, loss = 51579760322.02015686\n",
      "Validation score: 0.718305\n",
      "Iteration 70, loss = 51283629047.29447937\n",
      "Validation score: 0.720273\n",
      "Iteration 71, loss = 50782899908.41885376\n",
      "Validation score: 0.720079\n",
      "Iteration 72, loss = 50996109741.48014069\n",
      "Validation score: 0.713484\n",
      "Iteration 73, loss = 50903057135.71391296\n",
      "Validation score: 0.719309\n",
      "Iteration 74, loss = 50537553093.60075378\n",
      "Validation score: 0.724754\n",
      "Iteration 75, loss = 50730492107.37932587\n",
      "Validation score: 0.725014\n",
      "Iteration 76, loss = 50279271265.16606140\n",
      "Validation score: 0.719393\n",
      "Iteration 77, loss = 50378294330.65085602\n",
      "Validation score: 0.719113\n",
      "Iteration 78, loss = 50074968153.74427795\n",
      "Validation score: 0.725545\n",
      "Iteration 79, loss = 50046760694.65712738\n",
      "Validation score: 0.719145\n",
      "Iteration 80, loss = 50061131982.49112701\n",
      "Validation score: 0.724003\n",
      "Iteration 81, loss = 49683270367.38793945\n",
      "Validation score: 0.723786\n",
      "Iteration 82, loss = 49367766587.71184540\n",
      "Validation score: 0.725811\n",
      "Iteration 83, loss = 49365266722.08373260\n",
      "Validation score: 0.719899\n",
      "Iteration 84, loss = 49588700307.32492065\n",
      "Validation score: 0.715224\n",
      "Iteration 85, loss = 49418673133.22117615\n",
      "Validation score: 0.727683\n",
      "Iteration 86, loss = 49054377571.14825439\n",
      "Validation score: 0.729911\n",
      "Iteration 87, loss = 48719456062.10776520\n",
      "Validation score: 0.725529\n",
      "Iteration 88, loss = 49079573741.79872894\n",
      "Validation score: 0.721891\n",
      "Iteration 89, loss = 48807839722.75531769\n",
      "Validation score: 0.728932\n",
      "Iteration 90, loss = 48652122765.50996399\n",
      "Validation score: 0.725907\n",
      "Iteration 91, loss = 48347669324.90115356\n",
      "Validation score: 0.731148\n",
      "Iteration 92, loss = 48557871819.40808105\n",
      "Validation score: 0.718444\n",
      "Iteration 93, loss = 48277420222.26330566\n",
      "Validation score: 0.721141\n",
      "Iteration 94, loss = 48380455639.35833740\n",
      "Validation score: 0.723090\n",
      "Iteration 95, loss = 48044688940.24089813\n",
      "Validation score: 0.722324\n",
      "Iteration 96, loss = 47943973710.76434326\n",
      "Validation score: 0.719505\n",
      "Iteration 97, loss = 47834168289.87621307\n",
      "Validation score: 0.726088\n",
      "Iteration 98, loss = 47795509508.40981293\n",
      "Validation score: 0.726257\n",
      "Iteration 99, loss = 47911523164.38777924\n",
      "Validation score: 0.732017\n",
      "Iteration 100, loss = 47880401825.18689728\n",
      "Validation score: 0.728881\n",
      "Iteration 101, loss = 47489051465.11492157\n",
      "Validation score: 0.729684\n",
      "Iteration 102, loss = 47355671474.22821808\n",
      "Validation score: 0.725633\n",
      "Iteration 103, loss = 47321823385.81408691\n",
      "Validation score: 0.718644\n",
      "Iteration 104, loss = 47177465528.30341339\n",
      "Validation score: 0.733289\n",
      "Iteration 105, loss = 47132227298.24427795\n",
      "Validation score: 0.732438\n",
      "Iteration 106, loss = 46884540582.61531830\n",
      "Validation score: 0.729461\n",
      "Iteration 107, loss = 46800353284.72725677\n",
      "Validation score: 0.733526\n",
      "Iteration 108, loss = 46980710407.74008179\n",
      "Validation score: 0.731654\n",
      "Iteration 109, loss = 46823580813.06365204\n",
      "Validation score: 0.731651\n",
      "Iteration 110, loss = 46736953202.41348267\n",
      "Validation score: 0.736756\n",
      "Iteration 111, loss = 46552237705.49156189\n",
      "Validation score: 0.732146\n",
      "Iteration 112, loss = 46703000574.41637421\n",
      "Validation score: 0.733726\n",
      "Iteration 113, loss = 46563145561.44049835\n",
      "Validation score: 0.732527\n",
      "Iteration 114, loss = 46203659550.18667603\n",
      "Validation score: 0.730252\n",
      "Iteration 115, loss = 46390910472.36989594\n",
      "Validation score: 0.715469\n",
      "Iteration 116, loss = 46286243228.41011810\n",
      "Validation score: 0.736852\n",
      "Iteration 117, loss = 45818213334.80524445\n",
      "Validation score: 0.732790\n",
      "Iteration 118, loss = 45914245641.91691589\n",
      "Validation score: 0.723947\n",
      "Iteration 119, loss = 46004984893.22867584\n",
      "Validation score: 0.738556\n",
      "Iteration 120, loss = 45953935287.81452942\n",
      "Validation score: 0.733909\n",
      "Iteration 121, loss = 45759459382.37068176\n",
      "Validation score: 0.734360\n",
      "Iteration 122, loss = 45965256562.25268555\n",
      "Validation score: 0.738875\n",
      "Iteration 123, loss = 45673629531.46685028\n",
      "Validation score: 0.735797\n",
      "Iteration 124, loss = 45737226441.79428101\n",
      "Validation score: 0.734173\n",
      "Iteration 125, loss = 45231108540.31681824\n",
      "Validation score: 0.735450\n",
      "Iteration 126, loss = 45362991735.45524597\n",
      "Validation score: 0.733307\n",
      "Iteration 127, loss = 45557411924.77053070\n",
      "Validation score: 0.738080\n",
      "Iteration 128, loss = 45121159815.62339783\n",
      "Validation score: 0.736509\n",
      "Iteration 129, loss = 45011250653.52589417\n",
      "Validation score: 0.738323\n",
      "Iteration 130, loss = 44696842743.88749695\n",
      "Validation score: 0.741959\n",
      "Iteration 131, loss = 45101277572.23148346\n",
      "Validation score: 0.739345\n",
      "Iteration 132, loss = 44946547882.46430206\n",
      "Validation score: 0.734624\n",
      "Iteration 133, loss = 45340462574.27704620\n",
      "Validation score: 0.742885\n",
      "Iteration 134, loss = 44780951949.83144379\n",
      "Validation score: 0.737743\n",
      "Iteration 135, loss = 44434039055.05864716\n",
      "Validation score: 0.741203\n",
      "Iteration 136, loss = 44593955490.19281006\n",
      "Validation score: 0.733951\n",
      "Iteration 137, loss = 44733687059.50897980\n",
      "Validation score: 0.735708\n",
      "Iteration 138, loss = 44543896798.40501404\n",
      "Validation score: 0.741873\n",
      "Iteration 139, loss = 44203899812.73669434\n",
      "Validation score: 0.729248\n",
      "Iteration 140, loss = 44267160984.48433685\n",
      "Validation score: 0.740659\n",
      "Iteration 141, loss = 44172957893.86448669\n",
      "Validation score: 0.742702\n",
      "Iteration 142, loss = 43779874498.41842651\n",
      "Validation score: 0.720202\n",
      "Iteration 143, loss = 43888238329.56811523\n",
      "Validation score: 0.743708\n",
      "Iteration 144, loss = 43877733002.06481934\n",
      "Validation score: 0.745697\n",
      "Iteration 145, loss = 43690153076.82871246\n",
      "Validation score: 0.740019\n",
      "Iteration 146, loss = 43865381929.18025208\n",
      "Validation score: 0.724928\n",
      "Iteration 147, loss = 43657368325.58889008\n",
      "Validation score: 0.739921\n",
      "Iteration 148, loss = 43672696848.48696136\n",
      "Validation score: 0.735371\n",
      "Iteration 149, loss = 43415045842.73094940\n",
      "Validation score: 0.743645\n",
      "Iteration 150, loss = 43578942221.18071747\n",
      "Validation score: 0.747867\n",
      "Iteration 151, loss = 43411872564.91017914\n",
      "Validation score: 0.741250\n",
      "Iteration 152, loss = 43529817730.10858917\n",
      "Validation score: 0.732447\n",
      "Iteration 153, loss = 43105806409.37628937\n",
      "Validation score: 0.743181\n",
      "Iteration 154, loss = 43105887518.68669891\n",
      "Validation score: 0.739742\n",
      "Iteration 155, loss = 42921300715.07643127\n",
      "Validation score: 0.740716\n",
      "Iteration 156, loss = 43006400139.94055939\n",
      "Validation score: 0.745451\n",
      "Iteration 157, loss = 42741765935.87108612\n",
      "Validation score: 0.748154\n",
      "Iteration 158, loss = 42624669932.56763458\n",
      "Validation score: 0.741472\n",
      "Iteration 159, loss = 42984467120.31707001\n",
      "Validation score: 0.743681\n",
      "Iteration 160, loss = 42781784133.43762970\n",
      "Validation score: 0.751397\n",
      "Iteration 161, loss = 42453728945.01811981\n",
      "Validation score: 0.743775\n",
      "Iteration 162, loss = 42286005241.00572205\n",
      "Validation score: 0.745428\n",
      "Iteration 163, loss = 42252511131.67766571\n",
      "Validation score: 0.736194\n",
      "Iteration 164, loss = 42594739969.07461548\n",
      "Validation score: 0.740495\n",
      "Iteration 165, loss = 42320442324.43526459\n",
      "Validation score: 0.745648\n",
      "Iteration 166, loss = 42214467866.97139740\n",
      "Validation score: 0.747264\n",
      "Iteration 167, loss = 42279872027.59856415\n",
      "Validation score: 0.743418\n",
      "Iteration 168, loss = 42025491034.42841339\n",
      "Validation score: 0.746966\n",
      "Iteration 169, loss = 42036772676.55002594\n",
      "Validation score: 0.745942\n",
      "Iteration 170, loss = 41996672745.58623505\n",
      "Validation score: 0.750845\n",
      "Iteration 171, loss = 42196159452.03128815\n",
      "Validation score: 0.748132\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "0.7238787331626995, 0.5898970374207912\n"
     ]
    }
   ],
   "source": [
    "for feature_set in feature_sets:\n",
    "    print(f'Processing feature set: {feature_set}')\n",
    "\n",
    "    x_cols = feature_sets[feature_set]\n",
    "    x = df[x_cols]\n",
    "    x_train = x[:split_val]\n",
    "    x_val   = x[split_val:split_test]\n",
    "    x_test  = x[split_test:]\n",
    "\n",
    "    # Normalize the features to [0,1]\n",
    "    sc2 = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    x_train = sc2.fit_transform(x_train)\n",
    "    x_val   = sc2.transform(x_val)\n",
    "    x_test  = sc2.transform(x_test)\n",
    "\n",
    "    model = nn(\n",
    "        hidden_layer_sizes=(20, 20),\n",
    "        batch_size=200,\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=10,\n",
    "        verbose=True,\n",
    "        max_iter = 1000,\n",
    "        random_state=42,\n",
    "        validation_fraction=0.1,\n",
    "        learning_rate_init = 0.01\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    pickle.dump(model, open(f'../../output/models/neuralnet/neuralnet_{feature_set}.pkl', 'wb'))\n",
    "    print(f\"{model.score(x_val, y_val)}, {model.score(x_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
