{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b20e9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pickle, warnings, datetime, pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, MinMaxScaler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac759a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/processed/gdelt_pca.pkl', 'rb') as f:\n",
    "    pca_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d465aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which times to keep based on the stock data\n",
    "with open(r\"../../Data/Processed/stock_data_simple.pkl\", 'rb') as f:\n",
    "    stock_data = pickle.load(f)\n",
    "\n",
    "stock_data['date'] = stock_data.index.date\n",
    "days = list(stock_data['date'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e8dc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../../data/processed/gdelt_intermediate_cleaned.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0bf4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(subset=['GKGRECORDID'], inplace=True)\n",
    "\n",
    "df.index = df['GKGRECORDID']\n",
    "df.drop(columns=['GKGRECORDID'], inplace=True)\n",
    "df.drop(columns=['Positive Score','Negative Score','Activity Reference Density','Self/Group Reference Density'], inplace=True)\n",
    "df.drop(columns=[i for i in df.columns if 'SCOREDVALUE' in i], inplace=True)\n",
    "df.drop(columns=[i for i in df.columns if 'WORDCOUNT' in i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9faf026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, pca_data, on='GKGRECORDID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611aa96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V2SOURCECOMMONNAME',\n",
       " 'V2DOCUMENTIDENTIFIER',\n",
       " 'V1THEMES',\n",
       " 'datetime',\n",
       " 'date',\n",
       " 'airplane',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'Alaska Airlines',\n",
       " 'American Airlines',\n",
       " 'Delta Air Lines',\n",
       " 'Frontier Airlines',\n",
       " 'Hawaiian Airlines',\n",
       " 'JetBlue',\n",
       " 'Southwest Airlines',\n",
       " 'Spirit Airlines',\n",
       " 'Sun Country Airlines',\n",
       " 'United Airlines',\n",
       " 'Allegiant Air',\n",
       " 'article_title',\n",
       " 'Tone',\n",
       " 'Polarity',\n",
       " 'Word Count',\n",
       " 'PCA_GKG1_0',\n",
       " 'PCA_GKG1_1',\n",
       " 'PCA_GKG1_2',\n",
       " 'PCA_GKG1_3',\n",
       " 'PCA_GKG1_4',\n",
       " 'PCA_GKG1_5',\n",
       " 'PCA_GKG1_6',\n",
       " 'PCA_Scored_0',\n",
       " 'PCA_Scored_1',\n",
       " 'PCA_Scored_2',\n",
       " 'PCA_Scored_3',\n",
       " 'PCA_Scored_4',\n",
       " 'PCA_Scored_5',\n",
       " 'PCA_Scored_6',\n",
       " 'PCA_Scored_7',\n",
       " 'PCA_Scored_8',\n",
       " 'PCA_Scored_9',\n",
       " 'PCA_Scored_10',\n",
       " 'PCA_Scored_11',\n",
       " 'PCA_Scored_12',\n",
       " 'PCA_Scored_13',\n",
       " 'PCA_Scored_14',\n",
       " 'PCA_Scored_15',\n",
       " 'PCA_Scored_16',\n",
       " 'PCA_Scored_17',\n",
       " 'PCA_Scored_18',\n",
       " 'PCA_Scored_19',\n",
       " 'PCA_Scored_20',\n",
       " 'PCA_Scored_21',\n",
       " 'PCA_Scored_22',\n",
       " 'PCA_Scored_23',\n",
       " 'PCA_Scored_24',\n",
       " 'PCA_Scored_25',\n",
       " 'PCA_Scored_26',\n",
       " 'PCA_Scored_27',\n",
       " 'PCA_Scored_28',\n",
       " 'PCA_Scored_29',\n",
       " 'PCA_Scored_30',\n",
       " 'PCA_Scored_31',\n",
       " 'PCA_Scored_32',\n",
       " 'PCA_Scored_33',\n",
       " 'PCA_Scored_34',\n",
       " 'PCA_Scored_35',\n",
       " 'PCA_Scored_36',\n",
       " 'PCA_Scored_37',\n",
       " 'PCA_Scored_38',\n",
       " 'PCA_Scored_39',\n",
       " 'PCA_Word_0',\n",
       " 'PCA_Word_1',\n",
       " 'PCA_Word_2',\n",
       " 'PCA_Word_3',\n",
       " 'PCA_Word_4',\n",
       " 'PCA_Word_5',\n",
       " 'PCA_Word_6',\n",
       " 'PCA_Word_7',\n",
       " 'PCA_Word_8',\n",
       " 'PCA_Word_9',\n",
       " 'PCA_Word_10',\n",
       " 'PCA_Word_11',\n",
       " 'PCA_Word_12',\n",
       " 'PCA_Word_13',\n",
       " 'PCA_Word_14',\n",
       " 'PCA_Word_15',\n",
       " 'PCA_Word_16',\n",
       " 'PCA_Word_17',\n",
       " 'PCA_Word_18',\n",
       " 'PCA_Word_19',\n",
       " 'PCA_Word_20',\n",
       " 'PCA_Word_21',\n",
       " 'PCA_Word_22',\n",
       " 'PCA_Word_23',\n",
       " 'PCA_Word_24',\n",
       " 'PCA_Word_25',\n",
       " 'PCA_Word_26',\n",
       " 'PCA_Word_27',\n",
       " 'PCA_Word_28',\n",
       " 'PCA_Word_29',\n",
       " 'PCA_Word_30',\n",
       " 'PCA_Word_31',\n",
       " 'PCA_Word_32',\n",
       " 'PCA_Word_33',\n",
       " 'PCA_Word_34',\n",
       " 'PCA_Word_35',\n",
       " 'PCA_Word_36',\n",
       " 'PCA_Word_37',\n",
       " 'PCA_Word_38',\n",
       " 'PCA_Word_39',\n",
       " 'PCA_Word_40',\n",
       " 'PCA_Word_41',\n",
       " 'PCA_Word_42',\n",
       " 'PCA_Word_43',\n",
       " 'PCA_Word_44',\n",
       " 'PCA_Word_45',\n",
       " 'PCA_Word_46',\n",
       " 'PCA_Word_47',\n",
       " 'PCA_Word_48',\n",
       " 'PCA_Word_49',\n",
       " 'PCA_Word_50',\n",
       " 'PCA_Word_51',\n",
       " 'PCA_Word_52',\n",
       " 'PCA_Word_53',\n",
       " 'PCA_Word_54',\n",
       " 'PCA_Word_55',\n",
       " 'PCA_Word_56',\n",
       " 'PCA_Word_57',\n",
       " 'PCA_Word_58',\n",
       " 'PCA_Word_59',\n",
       " 'PCA_Word_60',\n",
       " 'PCA_Word_61',\n",
       " 'PCA_Word_62',\n",
       " 'PCA_Word_63',\n",
       " 'PCA_Word_64',\n",
       " 'PCA_Word_65',\n",
       " 'PCA_Word_66',\n",
       " 'PCA_Word_67',\n",
       " 'PCA_Word_68',\n",
       " 'PCA_Word_69',\n",
       " 'PCA_Word_70',\n",
       " 'PCA_Word_71',\n",
       " 'PCA_Word_72',\n",
       " 'PCA_Word_73',\n",
       " 'PCA_Word_74',\n",
       " 'PCA_Word_75',\n",
       " 'PCA_Word_76',\n",
       " 'PCA_Word_77',\n",
       " 'PCA_Word_78',\n",
       " 'PCA_Word_79',\n",
       " 'PCA_Word_80',\n",
       " 'PCA_Word_81',\n",
       " 'PCA_Word_82',\n",
       " 'PCA_Word_83',\n",
       " 'PCA_Word_84',\n",
       " 'PCA_Word_85',\n",
       " 'PCA_Word_86',\n",
       " 'PCA_Word_87',\n",
       " 'PCA_Word_88',\n",
       " 'PCA_Word_89',\n",
       " 'PCA_Word_90',\n",
       " 'PCA_Word_91',\n",
       " 'PCA_Word_92',\n",
       " 'PCA_Word_93',\n",
       " 'PCA_Word_94',\n",
       " 'PCA_Word_95',\n",
       " 'PCA_Word_96',\n",
       " 'PCA_Word_97',\n",
       " 'PCA_Word_98',\n",
       " 'PCA_Word_99']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c13e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topic-specific metrics columns\n",
    "df['Article Count'] = 1\n",
    "\n",
    "df['general'] = 1\n",
    "\n",
    "topics  = ['general','Alaska Airlines','American Airlines','Delta Air Lines','JetBlue','Southwest Airlines','United Airlines','Allegiant Air']\n",
    "metrics = ['Tone','Polarity','Word Count',\n",
    "           'PCA_GKG1_0','PCA_GKG1_1','PCA_GKG1_2','PCA_GKG1_3','PCA_GKG1_4',\n",
    "           'PCA_Scored_0','PCA_Scored_1','PCA_Scored_2','PCA_Scored_3','PCA_Scored_4',\n",
    "           'PCA_Word_0','PCA_Word_1','PCA_Word_2','PCA_Word_3','PCA_Word_4',\n",
    "           'Article Count']\n",
    "\n",
    "for topic in topics:\n",
    "    for metric in metrics:\n",
    "        df[f'{metric}_{topic}'] = df[metric] * df[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bc829965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grouped dataframe, grouped by datetime, that creates a sum for each metric\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "\n",
    "grouped_df = df.groupby('datetime').agg(\n",
    "    {f'{metric}_{topic}': ['sum'] for topic in topics for metric in metrics}\n",
    ")\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "grouped_df.columns = ['_'.join(col).strip().replace('_sum','') for col in grouped_df.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba12881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in all missing times\n",
    "start = datetime.datetime(2018, 1, 1, 0, 15, 0)\n",
    "end   = datetime.datetime(2025, 5, 31, 23, 45, 0)\n",
    "dates = pd.date_range(start=start, end=end, freq='15min')\n",
    "grouped_df = grouped_df.reindex(dates).reset_index()\n",
    "grouped_df = grouped_df.fillna(0)\n",
    "\n",
    "grouped_df['datetime'] = grouped_df['index']\n",
    "grouped_df.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f012e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from UTC to EST, accounting for daylight saving time\n",
    "grouped_df['datetime'] = pd.to_datetime(grouped_df['datetime'], utc=True)\n",
    "grouped_df['datetime_EST'] = grouped_df['datetime'].dt.tz_convert('America/New_York')\n",
    "grouped_df['time'] = grouped_df['datetime_EST'].dt.time\n",
    "grouped_df['date'] = grouped_df['datetime_EST'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97d572ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Handling after-hours articles #####\n",
    "\n",
    "# Join with stock data\n",
    "grouped_df['stock_time'] = np.where(grouped_df['date'].isin(days), grouped_df['datetime_EST'], pd.NaT)\n",
    "# Limit times after 15:45 and before 9:15\n",
    "grouped_df['stock_time'] = np.where(grouped_df['time'] > datetime.time(15,45,0), pd.NaT, grouped_df['stock_time'])\n",
    "grouped_df['stock_time'] = np.where(grouped_df['time'] < datetime.time(9,30,0) , pd.NaT, grouped_df['stock_time'])\n",
    "# format the stock_time column\n",
    "grouped_df['stock_time'] = pd.to_datetime(grouped_df['stock_time'])\n",
    "grouped_df = grouped_df.sort_values(by='datetime')\n",
    "# Backfill the stock_time2 column\n",
    "grouped_df['stock_time'] = grouped_df['stock_time'].ffill().bfill()\n",
    "# Remove the timezone information \n",
    "grouped_df['stock_time'] = grouped_df['stock_time'].dt.tz_localize(None)\n",
    "#grouped_df.drop(columns=['datetime', 'datetime_EST', 'time', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fa81d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice of window here ultimately affects how much after-hours time should be counted towards market open\n",
    "# For example, a 4-period window would mean that articles from 8:15 to 9:15 are counted towards the 9:30 period\n",
    "windows = [4, 8, 16, 48, 96]\n",
    "\n",
    "for window in windows:\n",
    "    for topic in topics:\n",
    "        for metric in metrics:\n",
    "            grouped_df[f'{metric}_{topic}_{window}'] = grouped_df[f'{metric}_{topic}'].rolling(window, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "401eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we keep the last of each stock time to remove duplicate values.\n",
    "grouped_df = grouped_df.drop_duplicates(subset=['stock_time'], keep='last')\n",
    "grouped_df.index = grouped_df['stock_time']\n",
    "grouped_df.drop(columns=['stock_time'], inplace=True)\n",
    "grouped_df.sort_index(inplace=True)\n",
    "grouped_df.drop(columns=['datetime','datetime_EST','time','date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7042e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to pickle object\n",
    "with open(r\"../../Data/Processed/GDELT_Clean_202506191330.pkl\", 'wb') as f:\n",
    "    pickle.dump(grouped_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the vars\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "for window in windows:\n",
    "    for topic in topics:\n",
    "        for metric in metrics:\n",
    "            grouped_df[f'{metric}_{topic}_{window}'] = scaler.fit_transform(grouped_df[[f'{metric}_{topic}_{window}']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svo-directed-practicum (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
