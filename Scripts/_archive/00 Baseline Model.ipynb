{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7d99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "import warnings, datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3f351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"../../data/raw/stock prices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a13e4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all csv files in path_to_data and all subfolders\n",
    "csv_files = []\n",
    "for root, dirs, files in os.walk(path_to_data):\n",
    "    for f in files:\n",
    "        if f.endswith('.csv'):\n",
    "            csv_files.append(os.path.join(root, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbb6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the files, limiting columns and appending airline tickers to a df\n",
    "for file in csv_files:\n",
    "    ticker = file.split('_')[0].split('\\\\')[-1].upper()  # Extract ticker from filename\n",
    "\n",
    "    if file == csv_files[0]:\n",
    "        df = pd.read_csv(file)\n",
    "        df['ticker'] = ticker\n",
    "    else:\n",
    "        df_temp = pd.read_csv(file)\n",
    "        df_temp['ticker'] = ticker\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd1c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd1a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Time' column to datetime format\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M')\n",
    "df['ti']=df['Time'].dt.time\n",
    "df.sort_values(by=['ticker', 'Time'], inplace=True)\n",
    "\n",
    "# More efficient approach for lagged variables\n",
    "for day_lag in range(1, 6):\n",
    "    df[f'Volume_Day_lag{day_lag:02d}'] = None\n",
    "    \n",
    "    for time_val in df['ti'].unique():\n",
    "        mask = df['ti'] == time_val\n",
    "        subset = df[mask].copy()\n",
    "        subset = subset.sort_values(['ticker', 'Time'])\n",
    "        \n",
    "        # Calculate lag for each ticker separately\n",
    "        lagged_values = subset.groupby('ticker')['Volume'].shift(day_lag)\n",
    "        df.loc[mask, f'Volume_Day_lag{day_lag:02d}'] = lagged_values.values\n",
    "\n",
    "df['Volume_Day_lagma5'] = df[['Volume_Day_lag01', 'Volume_Day_lag02', 'Volume_Day_lag03',\n",
    "                                         'Volume_Day_lag04', 'Volume_Day_lag05']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1139b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.sort_values(by=['Time', 'ticker'], inplace=True)\n",
    "df.index = df[['Time','ticker']]\n",
    "df['date'] = df['Time']\n",
    "df = df[df['date'] >= datetime.datetime(2018, 1, 1, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a72b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ticker'].isin(['AAL', 'ALGT', 'ALK', 'DAL', 'JBLU', 'LUV', 'UAL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60489106",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['Volume']\n",
    "x_cols = ['Volume_Day_lagma5']\n",
    "\n",
    "y = df[y_cols]\n",
    "x = df[x_cols]\n",
    "\n",
    "# Train/test splitting\n",
    "split_val  = round(0.8 * len(y))\n",
    "split_test = round(0.9 * len(y))\n",
    "\n",
    "y_train = y[:split_val]\n",
    "y_val   = y[split_val:split_test]\n",
    "y_test  = y[split_test:]\n",
    "\n",
    "x_train = x[:split_val]\n",
    "x_val   = x[split_val:split_test]\n",
    "x_test  = x[split_test:]\n",
    "\n",
    "# Normalize the features to [0,1]\n",
    "sc2 = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train = sc2.fit_transform(x_train)\n",
    "x_val   = sc2.transform(x_val)\n",
    "x_test  = sc2.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad8f7fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: 0.5595847093722299\n"
     ]
    }
   ],
   "source": [
    "ols = LinearRegression()\n",
    "ols.fit(x_train, y_train)\n",
    "\n",
    "x_eval = np.concatenate((x_val, x_test), axis=0)\n",
    "y_eval = y[split_val:]\n",
    "\n",
    "print(f\"OLS: {ols.score(x_eval, y_eval)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
